{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params\n",
    "DEBUG = True\n",
    "saveReport = True\n",
    "toPrint = True\n",
    "txt_label = \"Classification of integrated c1 and c2 CNVs samples\"\n",
    "\n",
    "to_save_euclidean_distances = True\n",
    "to_compute_euclidean_distances = True\n",
    "\n",
    "# feature selection: defaults are None\n",
    "# if not then abs_mean_filter has priority over topN if both not None\n",
    "abs_mean_filter = None   # default\n",
    "topN = None              # default\n",
    "# abs_mean_filter = 0.001  # nnz\n",
    "# abs_mean_filter = 0.1    # nnz_0.1\n",
    "abs_mean_filter = 0.2    # nnz_0.2\n",
    "# topN = 10                # top10\n",
    "# topN = 5                 # top5\n",
    "\n",
    "if abs_mean_filter is None and topN is None:\n",
    "    reportName = 'all_features'\n",
    "else:\n",
    "    if abs_mean_filter is not None:\n",
    "        reportName = 'nnz'+str(abs_mean_filter)+'_features'\n",
    "    else:\n",
    "        reportName = 'top'+str(topN)+'_features'\n",
    "        \n",
    "\n",
    "# train test split params\n",
    "split_train_size = 40\n",
    "split_random_state = 0\n",
    "\n",
    "# classification params\n",
    "classification_args = {\n",
    "    \"n_splits\": 10,\n",
    "    \"random_state\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting params\n",
    "\n",
    "with_swarm = False\n",
    "highRes = False\n",
    "if highRes:\n",
    "    img_ext = '.pdf'\n",
    "else:\n",
    "    img_ext = '.png'\n",
    "\n",
    "\n",
    "cnv_plot_kwargs = {\n",
    "    \"vmin\": -2,\n",
    "    \"vmax\": +2,\n",
    "    \"mincol\": \"red\",\n",
    "    \"midcol\": \"white\",\n",
    "    \"maxcol\": \"blue\",\n",
    "    \"function_dict\": None\n",
    "}\n",
    "\n",
    "var_plot_kwargs = {\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": 4,\n",
    "    \"mincol\": \"white\",\n",
    "    \"midcol\": \"orange\",\n",
    "    \"maxcol\": \"red\",\n",
    "    \"function_dict\": {\n",
    "        \"no mutation\": 0,\n",
    "        \"missense\": 1,\n",
    "        \"nonframeshiftIndel\": 2,\n",
    "        \"nonsense\": 3,\n",
    "        \"frameshiftIndel\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "mixed_plot_kwargs = {\n",
    "    \"vmin\": -4,\n",
    "    \"vmax\": +4,\n",
    "    \"mincol\": \"red\",\n",
    "    \"midcol\": \"white\",\n",
    "    \"maxcol\": \"purple\",\n",
    "    \"function_dict\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file\n",
    "cnv_data_fpath = \"output/headneck/integrate_cohorts/c1c2/CNV_mapped_filt/integrated_data.csv\"\n",
    "var_data_fpath = \"output/headneck/integrate_cohorts/c1c2/genepanel/integrated_data.csv\"\n",
    "\n",
    "# sample_info file\n",
    "sample_info_fpath = \"output/headneck/integrate_cohorts/c1c2/integrated_sample_info.csv\"\n",
    "sample_class_column = \"Relapsed\"\n",
    "class_labels = [\"relapsed\",\"NOTrelapsed\"]\n",
    "class_values = [1,0]\n",
    "\n",
    "# genes_info file\n",
    "# ideally we would have one file for all genes regardless of the dataset they come from\n",
    "# but in our case we had to gather this information during contruction of the data\n",
    "# that is why we should take into account all files from all the data we integrate\n",
    "#  -- in this case we integrate: oncoscan filtered by Nexus and ExCavator2 filtered by us (0.90 ProbCall) \n",
    "genes_info_names = ['c1_oncoscan_byNexus', 'c2_excavator2_byNexus_filt']\n",
    "genes_info_fpaths = []\n",
    "for name in genes_info_names:\n",
    "    genes_info_fpaths.append(\"output/headneck/setup_\"+name+\"/genes_info.csv\")\n",
    "chr_col = 'chr_int'\n",
    "gene_id_col = 'gene'\n",
    "\n",
    "# output dir\n",
    "output_directory = \"output/headneck/classification/notebook/\"+reportName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments to load the sample_info file\n",
    "sample_info_read_csv_kwargs = {\n",
    "    \"sep\": \"\\t\",\n",
    "    \"header\": 0,\n",
    "    \"col_as_index\":\"patientID\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "genepanel_fpath = \"output/headneck/setup_c1_genepanel/process_select_primary/data_processed.csv\"\n",
    "genepanel_key_name = 'genepanel'\n",
    "\n",
    "feature_dirs = ['c1_prmr_OncFltNxEx', 'c2_ExcvFltNxEx', 'c1_prmr_mapped_c2_CnvNxEx', 'c1_prmr_mapped_c2_Cnv', 'c1_prmr_mapped_c2_CnvMixedNxEx']\n",
    "feature_key_names = ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx', 'c3_Cnv', 'c3_CnvMixedNxEx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose conbinations of features\n",
    "feature_combinations = {\n",
    "    'GnPnl_c1_OncFltNxEx': ['genepanel', 'c1_OncFltNxEx'], # 26 union\n",
    "    'GnPnl_c2_ExcvFltNxEx': ['genepanel', 'c2_ExcvFltNxEx'],  # 45 union\n",
    "    'GnPnl_c3_CnvNxEx': ['genepanel', 'c3_CnvNxEx'],  # 106 union\n",
    "#     'c3_CNVmix': ['c3_CnvNxEx', 'c3_Cnv', 'c3_CnvMixedNxEx'], # 1 common, 1337 union\n",
    "    'CNVc1c2': ['c1_OncFltNxEx', 'c2_ExcvFltNxEx'], # 45 union, 0 common\n",
    "    'GnPnl_CNVc1c2': ['genepanel', 'c1_OncFltNxEx', 'c2_ExcvFltNxEx'], # 58 union\n",
    "    'CNVcAll': ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx'], # 127 union\n",
    "    'GnPnl_CNVcAll': ['genepanel', 'c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx'] # 140 union\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from omics_processing.io import (\n",
    "    set_directory, load_clinical\n",
    ")\n",
    "from omics_processing.remove_duplicates import (\n",
    "    remove_andSave_duplicates\n",
    ")\n",
    "from gene_signatures.core import (\n",
    "    custom_div_cmap,\n",
    "    get_chr_ticks,\n",
    "    choose_samples,\n",
    "    parse_arg_type,\n",
    "    boxplot,\n",
    "    set_heatmap_size,\n",
    "    set_cbar_ticks,\n",
    "    edit_names_with_duplicates,\n",
    "    plot_confusion_matrix,\n",
    "    define_plot_args,\n",
    "    plot_scatter_scores,\n",
    "    plot_roc_with_std_for_one_model,\n",
    "    plot_roc_for_many_models,\n",
    "    compute_and_plot_confusion_matrices,\n",
    "    plot_prediction_counts_per_class,\n",
    "    plot_data_heatmap,\n",
    "    extract_gene_set,\n",
    "    save_image,\n",
    "    check_path_integrity\n",
    ")\n",
    "\n",
    "# basic imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from natsort import natsorted, index_natsorted\n",
    "import math\n",
    "import logging\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from distutils.util import strtobool\n",
    "from scipy.stats import binom_test\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from functools import reduce\n",
    "\n",
    "# plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "script_path = os.getcwd()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_classification(\n",
    "        dat, dat_target, random_state=None, n_splits=10):\n",
    "\n",
    "    min_class_count = np.unique(dat_target, return_counts=True)[1].min()\n",
    "    if n_splits is not None:\n",
    "        if (n_splits > dat.shape[0]) or (n_splits > min_class_count):\n",
    "            n_splits = min_class_count\n",
    "    if random_state is not None:\n",
    "        random_state = parse_arg_type(random_state, int)\n",
    "    else:\n",
    "        random_state = 0\n",
    "    logger.info(\n",
    "        \"model: svm.LinearSVC with l2 penalty, squared_hinge loss \" +\n",
    "        \"and random_state: \"+str(random_state)\n",
    "    )\n",
    "    model = svm.LinearSVC(\n",
    "        penalty='l2', C=1, random_state=random_state,\n",
    "        loss='squared_hinge', dual=False\n",
    "    )\n",
    "\n",
    "    logger.info(\"Running classification...\")\n",
    "    dat = dat.copy()\n",
    "    dat_target = dat_target.copy()\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    k_fold = StratifiedKFold(n_splits=n_splits)\n",
    "    cross_val_scores = []\n",
    "    all_coefs = np.zeros((n_splits, dat.shape[1]))\n",
    "    y_train_predictions = pd.Series(index=y.index)\n",
    "    y_train_predictions.name = \"train_predictions\"\n",
    "    \n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    interps = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    split_i = 0\n",
    "    for train_indices, test_indices in k_fold.split(X, y):\n",
    "        X_train = dat.iloc[train_indices]\n",
    "        y_train = dat_target.iloc[train_indices]\n",
    "        \n",
    "        X_crossval = dat.iloc[test_indices]\n",
    "        y_crossval = dat_target.iloc[test_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        all_coefs[split_i:split_i+1, :] = model.coef_[0]\n",
    "        cross_val_scores.append(model.score(X_crossval, y_crossval))\n",
    "        y_train_predictions.iloc[test_indices] = model.predict(X_crossval)\n",
    "        \n",
    "        \n",
    "        y_proba = model.decision_function(X_crossval)\n",
    "        # clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "        # clf.fit(X_crossval, y_crossval)\n",
    "        # y_proba = clf.predict_proba(X_crossval)\n",
    "        # Compute ROC curve and area the curve\n",
    "        # fpr, tpr, thresholds = roc_curve(y_crossval, y_proba[:, 1])\n",
    "        fpr, tpr, thresholds = roc_curve(y_crossval, y_proba)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        interps.append(interp(mean_fpr, fpr, tpr))\n",
    "        interps[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        split_i += 1\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    model.fit(X, y)\n",
    "\n",
    "    all_coefs = pd.DataFrame(all_coefs, columns=dat.columns.values)\n",
    "\n",
    "    return model, all_coefs, y_train_predictions, cross_val_scores, fprs, tprs, interps, aucs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly set file paths\n",
    "try:\n",
    "    os.path.exists(MainDataDir)\n",
    "except:\n",
    "    MainDataDir = os.path.join(script_path, '..','..', 'data')\n",
    "    logger.debug(\"set MainDataDir:\\n\"+MainDataDir)\n",
    "\n",
    "# data output\n",
    "output_directory = check_path_integrity(output_directory, rootDir=MainDataDir, name=\"output\", force=True)\n",
    "\n",
    "if DEBUG:\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:gene_signatures.core:set cnv data fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/integrate_cohorts/c1c2/CNV_mapped_filt/integrated_data.csv\n",
      "DEBUG:gene_signatures.core:set var data fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/integrate_cohorts/c1c2/genepanel/integrated_data.csv\n",
      "DEBUG:gene_signatures.core:set sample_info fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/integrate_cohorts/c1c2/integrated_sample_info.csv\n",
      "DEBUG:gene_signatures.core:set gene_info fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/setup_c1_oncoscan_byNexus/genes_info.csv\n",
      "DEBUG:gene_signatures.core:set gene_info fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/setup_c2_excavator2_byNexus_filt/genes_info.csv\n"
     ]
    }
   ],
   "source": [
    "# cnv data input\n",
    "cnv_data_fpath = check_path_integrity(cnv_data_fpath, rootDir=MainDataDir, name=\"cnv data\")\n",
    "\n",
    "# genepanel data input\n",
    "var_data_fpath = check_path_integrity(var_data_fpath, rootDir=MainDataDir, name=\"var data\")\n",
    "\n",
    "# sample info input\n",
    "sample_info_fpath = check_path_integrity(sample_info_fpath, rootDir=MainDataDir, name=\"sample_info\")\n",
    "\n",
    "# gene info input\n",
    "for i,fpath in enumerate(genes_info_fpaths):\n",
    "    genes_info_fpaths[i] = check_path_integrity(fpath, rootDir=MainDataDir, name=\"gene_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:gene_signatures.core:set genepanel features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/setup_c1_genepanel/process_select_primary/data_processed.csv\n",
      "DEBUG:gene_signatures.core:set c1_OncFltNxEx features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/feature_selection/c1_prmr_OncFltNxEx/featsel_results.csv\n",
      "DEBUG:gene_signatures.core:set c2_ExcvFltNxEx features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/feature_selection/c2_ExcvFltNxEx/featsel_results.csv\n",
      "DEBUG:gene_signatures.core:set c3_CnvNxEx features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/feature_selection/c1_prmr_mapped_c2_CnvNxEx/featsel_results.csv\n",
      "DEBUG:gene_signatures.core:set c3_Cnv features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/feature_selection/c1_prmr_mapped_c2_Cnv/featsel_results.csv\n",
      "DEBUG:gene_signatures.core:set c3_CnvMixedNxEx features fpath:\n",
      "/Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/feature_selection/c1_prmr_mapped_c2_CnvMixedNxEx/featsel_results.csv\n"
     ]
    }
   ],
   "source": [
    "# fpaths_dict\n",
    "fpaths_dict = {}\n",
    "fpaths_dict[genepanel_key_name] = check_path_integrity(genepanel_fpath, rootDir=MainDataDir, name=\"genepanel features\")\n",
    "\n",
    "for _f, _k in zip(feature_dirs, feature_key_names):\n",
    "    fpath = \"output/headneck/feature_selection/\"+_f+\"/featsel_results.csv\"\n",
    "    fpaths_dict[_k] = check_path_integrity(fpath, rootDir=MainDataDir, name=_k+\" features\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loaded cnv data file with shape: (61, 18417)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AADACL3__CNV</th>\n",
       "      <th>AADACL4__CNV</th>\n",
       "      <th>ACOT7__CNV</th>\n",
       "      <th>AGTRAP__CNV</th>\n",
       "      <th>AJAP1__CNV</th>\n",
       "      <th>ANGPTL7__CNV</th>\n",
       "      <th>APITD1-CORT__CNV</th>\n",
       "      <th>C1orf127__CNV</th>\n",
       "      <th>C1orf158__CNV</th>\n",
       "      <th>C1orf167__CNV</th>\n",
       "      <th>...</th>\n",
       "      <th>TTTY8__CNV</th>\n",
       "      <th>TTTY9B__CNV</th>\n",
       "      <th>USP9Y__CNV</th>\n",
       "      <th>UTY__CNV</th>\n",
       "      <th>VCY__CNV</th>\n",
       "      <th>XKRY__CNV</th>\n",
       "      <th>ZFY__CNV</th>\n",
       "      <th>BCORP1__CNV</th>\n",
       "      <th>CD24__CNV</th>\n",
       "      <th>KDM5D__CNV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2Rpr</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 18417 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AADACL3__CNV  AADACL4__CNV  ACOT7__CNV  AGTRAP__CNV  AJAP1__CNV  \\\n",
       "1Rpr           0.0           0.0         0.0          0.0         0.0   \n",
       "2Rpr          -1.0          -1.0        -1.0         -1.0        -1.0   \n",
       "3Rpr           0.0           0.0         0.0          0.0         0.0   \n",
       "4Rpr           0.0           0.0         0.0          0.0         0.0   \n",
       "5Rpr           0.0           0.0         0.0          0.0         0.0   \n",
       "\n",
       "      ANGPTL7__CNV  APITD1-CORT__CNV  C1orf127__CNV  C1orf158__CNV  \\\n",
       "1Rpr           0.0               0.0            0.0            0.0   \n",
       "2Rpr          -1.0              -1.0           -1.0           -1.0   \n",
       "3Rpr           0.0               0.0            0.0            0.0   \n",
       "4Rpr           0.0               0.0            0.0            0.0   \n",
       "5Rpr           0.0               0.0            0.0            0.0   \n",
       "\n",
       "      C1orf167__CNV     ...      TTTY8__CNV  TTTY9B__CNV  USP9Y__CNV  \\\n",
       "1Rpr            0.0     ...             0.0          0.0         0.0   \n",
       "2Rpr           -1.0     ...             0.0          0.0         0.0   \n",
       "3Rpr            0.0     ...             0.0         -2.0         0.0   \n",
       "4Rpr            0.0     ...             0.0          0.0         0.0   \n",
       "5Rpr            0.0     ...            -2.0         -2.0        -2.0   \n",
       "\n",
       "      UTY__CNV  VCY__CNV  XKRY__CNV  ZFY__CNV  BCORP1__CNV  CD24__CNV  \\\n",
       "1Rpr       0.0       0.0        0.0       0.0          0.0        0.0   \n",
       "2Rpr       0.0       0.0        0.0       0.0          0.0        0.0   \n",
       "3Rpr       0.0       0.0       -2.0       0.0         -2.0       -2.0   \n",
       "4Rpr       0.0       0.0        0.0       0.0          0.0        0.0   \n",
       "5Rpr      -2.0      -2.0       -2.0      -2.0         -2.0       -2.0   \n",
       "\n",
       "      KDM5D__CNV  \n",
       "1Rpr         0.0  \n",
       "2Rpr         0.0  \n",
       "3Rpr        -2.0  \n",
       "4Rpr         0.0  \n",
       "5Rpr        -2.0  \n",
       "\n",
       "[5 rows x 18417 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load cnv data\n",
    "cnv_data = pd.read_csv(cnv_data_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded cnv data file with shape: '+str(cnv_data.shape))\n",
    "\n",
    "cnv_data.columns += \"__CNV\"\n",
    "\n",
    "cnv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loaded var data file with shape: (63, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAF__VAR</th>\n",
       "      <th>CASP8__VAR</th>\n",
       "      <th>CDKN2A__VAR</th>\n",
       "      <th>FAT1__VAR</th>\n",
       "      <th>FBXW7__VAR</th>\n",
       "      <th>KMT2D__VAR</th>\n",
       "      <th>MED1__VAR</th>\n",
       "      <th>NRAS__VAR</th>\n",
       "      <th>PIK3CA__VAR</th>\n",
       "      <th>SYNE1__VAR</th>\n",
       "      <th>SYNE2__VAR</th>\n",
       "      <th>TP53__VAR</th>\n",
       "      <th>TP63__VAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Rpr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5Rpr</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRAF__VAR  CASP8__VAR  CDKN2A__VAR  FAT1__VAR  FBXW7__VAR  KMT2D__VAR  \\\n",
       "1Rpr        0.0         0.0          0.0        1.0         0.0         0.0   \n",
       "2Rpr        0.0         0.0          0.0        1.0         0.0         0.0   \n",
       "3Rpr        0.0         0.0          2.0        1.0         0.0         3.0   \n",
       "4Rpr        1.0         0.0          0.0        1.0         0.0         0.0   \n",
       "5Rpr        0.0         0.0          0.0        0.0         0.0         0.0   \n",
       "\n",
       "      MED1__VAR  NRAS__VAR  PIK3CA__VAR  SYNE1__VAR  SYNE2__VAR  TP53__VAR  \\\n",
       "1Rpr        0.0        0.0          0.0         0.0         0.0        3.0   \n",
       "2Rpr        0.0        1.0          0.0         0.0         0.0        0.0   \n",
       "3Rpr        0.0        0.0          0.0         4.0         0.0        0.0   \n",
       "4Rpr        0.0        0.0          0.0         1.0         0.0        0.0   \n",
       "5Rpr        0.0        0.0          1.0         0.0         0.0        1.0   \n",
       "\n",
       "      TP63__VAR  \n",
       "1Rpr        0.0  \n",
       "2Rpr        0.0  \n",
       "3Rpr        0.0  \n",
       "4Rpr        0.0  \n",
       "5Rpr        0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load genepanel data\n",
    "var_data = pd.read_csv(var_data_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded var data file with shape: '+str(var_data.shape))\n",
    "\n",
    "var_data.columns += \"__VAR\"\n",
    "\n",
    "var_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:omics_processing.io:Load clinical file: /Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/integrate_cohorts/c1c2/integrated_sample_info.csv\n",
      "INFO:__main__:loaded sample_info file with shape: (75, 11)\n",
      "INFO:__main__:keeping part of sample_infowith shape: (61, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>varID</th>\n",
       "      <th>cnvID</th>\n",
       "      <th>patient</th>\n",
       "      <th>tumor</th>\n",
       "      <th>class_description</th>\n",
       "      <th>Tcode</th>\n",
       "      <th>Ccode</th>\n",
       "      <th>dataset</th>\n",
       "      <th>Local_Control</th>\n",
       "      <th>Relapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1Rpr</th>\n",
       "      <td>0</td>\n",
       "      <td>Rad2_MR</td>\n",
       "      <td>DS-107_0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>primary</td>\n",
       "      <td>Responder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2Rpr</th>\n",
       "      <td>1</td>\n",
       "      <td>Rad3_MR</td>\n",
       "      <td>DS-107_0003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>primary</td>\n",
       "      <td>Responder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Rpr</th>\n",
       "      <td>2</td>\n",
       "      <td>Rad4_MR</td>\n",
       "      <td>DS-107_0004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>primary</td>\n",
       "      <td>Responder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Rpr</th>\n",
       "      <td>3</td>\n",
       "      <td>Rad5_MR</td>\n",
       "      <td>DS-107_0005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>primary</td>\n",
       "      <td>Responder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5Rpr</th>\n",
       "      <td>4</td>\n",
       "      <td>Rad6_MR</td>\n",
       "      <td>DS-107_0006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>primary</td>\n",
       "      <td>Responder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    varID        cnvID  patient    tumor class_description  \\\n",
       "1Rpr           0  Rad2_MR  DS-107_0002      1.0  primary         Responder   \n",
       "2Rpr           1  Rad3_MR  DS-107_0003      2.0  primary         Responder   \n",
       "3Rpr           2  Rad4_MR  DS-107_0004      3.0  primary         Responder   \n",
       "4Rpr           3  Rad5_MR  DS-107_0005      4.0  primary         Responder   \n",
       "5Rpr           4  Rad6_MR  DS-107_0006      5.0  primary         Responder   \n",
       "\n",
       "      Tcode  Ccode  dataset  Local_Control  Relapsed  \n",
       "1Rpr    0.0    0.0        0            NaN       0.0  \n",
       "2Rpr    0.0    0.0        0            NaN       0.0  \n",
       "3Rpr    0.0    0.0        0            NaN       0.0  \n",
       "4Rpr    0.0    0.0        0            NaN       0.0  \n",
       "5Rpr    0.0    0.0        0            NaN       0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load info table of samples\n",
    "sample_info = load_clinical(\n",
    "    sample_info_fpath, **sample_info_read_csv_kwargs)\n",
    "logger.info('loaded sample_info file with shape: '+str(sample_info.shape))\n",
    "\n",
    "sample_info = sample_info.loc[cnv_data.index,:]\n",
    "logger.info('keeping part of sample_infowith shape: '+str(sample_info.shape))\n",
    "\n",
    "sample_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:__main__:loaded a genes info file with shape: (23060, 8)\n",
      "from: /Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/setup_c1_oncoscan_byNexus/genes_info.csv\n",
      "INFO:__main__:loaded a genes info file with shape: (24962, 8)\n",
      "from: /Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/setup_c2_excavator2_byNexus_filt/genes_info.csv\n",
      "INFO:__main__:FINAL genes info file with shape: (18417, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>gene</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>chr</th>\n",
       "      <th>chr_gene</th>\n",
       "      <th>chr_int</th>\n",
       "      <th>toNatSort</th>\n",
       "      <th>order__c2_excavator2_byNexus_filt</th>\n",
       "      <th>start__c2_excavator2_byNexus_filt</th>\n",
       "      <th>end__c2_excavator2_byNexus_filt</th>\n",
       "      <th>chr__c2_excavator2_byNexus_filt</th>\n",
       "      <th>chr_gene__c2_excavator2_byNexus_filt</th>\n",
       "      <th>chr_int__c2_excavator2_byNexus_filt</th>\n",
       "      <th>toNatSort__c2_excavator2_byNexus_filt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AADACL3__CNV</td>\n",
       "      <td>3398984</td>\n",
       "      <td>12860791</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AADACL3</td>\n",
       "      <td>1</td>\n",
       "      <td>1:3398984:12860791</td>\n",
       "      <td>25</td>\n",
       "      <td>65409</td>\n",
       "      <td>25573512</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AADACL3</td>\n",
       "      <td>1</td>\n",
       "      <td>1:65409:25573512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AADACL4__CNV</td>\n",
       "      <td>3398984</td>\n",
       "      <td>12860791</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AADACL4</td>\n",
       "      <td>1</td>\n",
       "      <td>1:3398984:12860791</td>\n",
       "      <td>26</td>\n",
       "      <td>65409</td>\n",
       "      <td>25573512</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AADACL4</td>\n",
       "      <td>1</td>\n",
       "      <td>1:65409:25573512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACOT7__CNV</td>\n",
       "      <td>3398984</td>\n",
       "      <td>12860791</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:ACOT7</td>\n",
       "      <td>1</td>\n",
       "      <td>1:3398984:12860791</td>\n",
       "      <td>28</td>\n",
       "      <td>65409</td>\n",
       "      <td>25573512</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:ACOT7</td>\n",
       "      <td>1</td>\n",
       "      <td>1:65409:25573512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AGTRAP__CNV</td>\n",
       "      <td>3398984</td>\n",
       "      <td>12860791</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AGTRAP</td>\n",
       "      <td>1</td>\n",
       "      <td>1:3398984:12860791</td>\n",
       "      <td>33</td>\n",
       "      <td>65409</td>\n",
       "      <td>25573512</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AGTRAP</td>\n",
       "      <td>1</td>\n",
       "      <td>1:65409:25573512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AJAP1__CNV</td>\n",
       "      <td>3398984</td>\n",
       "      <td>12860791</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AJAP1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:3398984:12860791</td>\n",
       "      <td>34</td>\n",
       "      <td>65409</td>\n",
       "      <td>25573512</td>\n",
       "      <td>chr1</td>\n",
       "      <td>chr1:AJAP1</td>\n",
       "      <td>1</td>\n",
       "      <td>1:65409:25573512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order          gene    start       end   chr      chr_gene chr_int  \\\n",
       "0      0  AADACL3__CNV  3398984  12860791  chr1  chr1:AADACL3       1   \n",
       "1      1  AADACL4__CNV  3398984  12860791  chr1  chr1:AADACL4       1   \n",
       "2      2    ACOT7__CNV  3398984  12860791  chr1    chr1:ACOT7       1   \n",
       "3      3   AGTRAP__CNV  3398984  12860791  chr1   chr1:AGTRAP       1   \n",
       "4      4    AJAP1__CNV  3398984  12860791  chr1    chr1:AJAP1       1   \n",
       "\n",
       "            toNatSort  order__c2_excavator2_byNexus_filt  \\\n",
       "0  1:3398984:12860791                                 25   \n",
       "1  1:3398984:12860791                                 26   \n",
       "2  1:3398984:12860791                                 28   \n",
       "3  1:3398984:12860791                                 33   \n",
       "4  1:3398984:12860791                                 34   \n",
       "\n",
       "   start__c2_excavator2_byNexus_filt  end__c2_excavator2_byNexus_filt  \\\n",
       "0                              65409                         25573512   \n",
       "1                              65409                         25573512   \n",
       "2                              65409                         25573512   \n",
       "3                              65409                         25573512   \n",
       "4                              65409                         25573512   \n",
       "\n",
       "  chr__c2_excavator2_byNexus_filt chr_gene__c2_excavator2_byNexus_filt  \\\n",
       "0                            chr1                         chr1:AADACL3   \n",
       "1                            chr1                         chr1:AADACL4   \n",
       "2                            chr1                           chr1:ACOT7   \n",
       "3                            chr1                          chr1:AGTRAP   \n",
       "4                            chr1                           chr1:AJAP1   \n",
       "\n",
       "  chr_int__c2_excavator2_byNexus_filt toNatSort__c2_excavator2_byNexus_filt  \n",
       "0                                   1                      1:65409:25573512  \n",
       "1                                   1                      1:65409:25573512  \n",
       "2                                   1                      1:65409:25573512  \n",
       "3                                   1                      1:65409:25573512  \n",
       "4                                   1                      1:65409:25573512  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load info table of genes\n",
    "dfs = []\n",
    "for i, fpath in enumerate(genes_info_fpaths):\n",
    "    df = pd.read_csv(fpath, sep='\\t', header=0, index_col=0)\n",
    "    df.columns.name = genes_info_names[i]\n",
    "    dfs.append(df)\n",
    "    logger.info('loaded a genes info file with shape: '+str(df.shape)+'\\nfrom: '+fpath)\n",
    "\n",
    "genes_info = reduce(\n",
    "    lambda left,right: pd.merge(left, right, on=gene_id_col, how='inner', suffixes=['','__'+str(right.columns.name)]), dfs)\n",
    "logger.info('FINAL genes info file with shape: '+str(genes_info.shape))\n",
    "\n",
    "genes_info[gene_id_col] += \"__CNV\"\n",
    "\n",
    "genes_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Rpr    0.0\n",
       "2Rpr    0.0\n",
       "3Rpr    0.0\n",
       "4Rpr    0.0\n",
       "5Rpr    0.0\n",
       "Name: Relapsed, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the ground truth\n",
    "ground_truth = sample_info.loc[cnv_data.index, sample_class_column]\n",
    "\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plots\n",
    "class_labels = np.array(class_labels)\n",
    "class_values = np.array(class_values)\n",
    "\n",
    "adict = define_plot_args(**cnv_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "cnv_plot_kwargs.update(adict)\n",
    "\n",
    "adict = define_plot_args(**var_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "var_plot_kwargs.update(adict)\n",
    "\n",
    "adict = define_plot_args(**mixed_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "mixed_plot_kwargs.update(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gene_signatures.core:Save figure in: /Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/classification/notebook/nnz0.2_features/Fig_heatmap_var_data.png\n"
     ]
    }
   ],
   "source": [
    "#  Plot Heatmap of genepanel_data\n",
    "plot_data_heatmap(\n",
    "    var_data, ground_truth, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var data: '+str(var_data.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gene_signatures.core:Save figure in: /Users/lle/GitRepos/myRepos/gene_signatures/examples/notebooks/../../data/output/headneck/classification/notebook/nnz0.2_features/Fig_heatmap_cnv_data.png\n"
     ]
    }
   ],
   "source": [
    "#  Plot Heatmap of cnv_data w/ duplicates\n",
    "xlabels, xpos = get_chr_ticks(\n",
    "    genes_info, cnv_data, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    cnv_data, ground_truth, xlabels, xpos, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv data: '+str(cnv_data.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:omics_processing.remove_duplicates:Load data from input.\n",
      "INFO:omics_processing.remove_duplicates:size before checking for duplicate columns: (61, 18417)\n",
      "INFO:omics_processing.remove_duplicates:computing genes euclidean distances...\n"
     ]
    }
   ],
   "source": [
    "# remove all zero columns!\n",
    "orphancols = np.where(abs(cnv_data).sum(axis=0) == 0)[0]\n",
    "if len(orphancols) > 0:\n",
    "    logger.warning('removing '+str(len(orphancols))+' genes from cnv data with zero columns!')\n",
    "    cols2drop = cnv_data.columns.values[orphancols]\n",
    "    cnv_data = cnv_data.drop(cols2drop, axis=1).copy()\n",
    "\n",
    "# REMOVE DUPLICATES!!!!\n",
    "cnv_data_uniq, dupldict, wo_dupl_set, all_dupl_set = remove_andSave_duplicates(\n",
    "    cnv_data, to_compute_euclidean_distances=to_compute_euclidean_distances,\n",
    "    to_save_euclidean_distances=to_save_euclidean_distances, to_save_output=True,\n",
    "    output_filename='cnv_data_wo_duplicates',\n",
    "    output_directory=output_directory\n",
    ")\n",
    "single_dupl_set = set(dupldict.keys())\n",
    "\n",
    "_countA = len(set.union(single_dupl_set, wo_dupl_set))\n",
    "_countB = cnv_data_uniq.shape[1]\n",
    "if not _countA == _countB:\n",
    "    print(\n",
    "        'ERROR: inconsistencies in the final uniq gene count!\\n'+\n",
    "        str(_countA)+' genes that should be in the uniq dataset VS. '+\n",
    "        str(_countB)+' genes that are'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of cnv data w/o duplicates\n",
    "xlabels_uniq, xpos_uniq = get_chr_ticks(\n",
    "    genes_info, cnv_data_uniq, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    cnv_data_uniq, ground_truth, xlabels_uniq, xpos_uniq, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv data w/o duplicates: '+str(cnv_data_uniq.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_uniq\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine var and cnv features\n",
    "data_uniq = pd.concat([cnv_data_uniq, var_data], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of mixed data w/o duplicates\n",
    "plot_data_heatmap(\n",
    "    data_uniq, ground_truth, None, None, **mixed_plot_kwargs\n",
    ")\n",
    "plt.title('mixed data w/o duplicates: '+str(data_uniq.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_mixed_data_uniq\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train-test ONCE!\n",
    "stratify_by = pd.concat([ground_truth, sample_info['dataset']], axis=1, sort=False)\n",
    "stratify_by = stratify_by.loc[ground_truth.index]\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data_uniq, ground_truth,\n",
    "    train_size=split_train_size,\n",
    "    test_size=None,\n",
    "    random_state=split_random_state,\n",
    "    stratify=stratify_by\n",
    ")\n",
    "\n",
    "cnv_data_train = cnv_data.loc[data_train.index,:].copy()\n",
    "cnv_data_test = cnv_data.loc[data_test.index,:].copy()\n",
    "\n",
    "\n",
    "var_data_train = var_data.loc[data_train.index,:].copy()\n",
    "var_data_test = var_data.loc[data_test.index,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify_by.hist()\n",
    "plt.suptitle('all '+str(ground_truth.shape[0])+' samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_all\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[cnv_data_train.index].hist()\n",
    "plt.suptitle(str(y_train.shape[0])+' train samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_train\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[cnv_data_test.index].hist()\n",
    "plt.suptitle(str(y_test.shape[0])+' test samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels_train, xpos_train = get_chr_ticks(\n",
    "    genes_info, cnv_data_train, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "xlabels_test, xpos_test = get_chr_ticks(\n",
    "    genes_info, cnv_data_test, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "#  Plot Heatmap of train cnv data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    cnv_data_train, y_train, xlabels_train, xpos_train, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv train data: '+str(cnv_data_train.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_train\", img_ext=img_ext)\n",
    "\n",
    "#  Plot Heatmap of test cnv data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    cnv_data_test, y_test, xlabels_test, xpos_test, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv test data: '+str(cnv_data_test.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of train var data\n",
    "plot_data_heatmap(\n",
    "    var_data_train, y_train, None, None, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var train data: '+str(var_data_train.shape[1])+' genes')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data_train\", img_ext=img_ext)\n",
    "\n",
    "#  Plot Heatmap of test var data\n",
    "plot_data_heatmap(\n",
    "    var_data_test, y_test, None, None, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var test data: '+str(var_data_test.shape[1])+' genes')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cnv_data_genes = set(cnv_data.columns.values)\n",
    "all_cnv_data_genes_uniq = set(cnv_data_uniq.columns.values)\n",
    "\n",
    "all_var_data_genes = set(var_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {}\n",
    "features_sets = {}\n",
    "for key in fpaths_dict:\n",
    "    n_total_pre_filt = n_total_pre_top = None\n",
    "    df = pd.read_csv(fpaths_dict[key], sep='\\t', header=0, index_col=0)\n",
    "    \n",
    "    if genepanel_key_name in key:\n",
    "        df.columns += \"__VAR\"\n",
    "        features_sets[key] = set(df.columns.values)\n",
    "        n_final = len(features_sets[key])\n",
    "        n_unique = n_final\n",
    "    else:\n",
    "        features_dict[key] = df\n",
    "        if abs_mean_filter is not None:\n",
    "            temp = extract_gene_set(df)\n",
    "            n_total_pre_filt = n_total = len(temp)\n",
    "            df = df[df['abs_mean_coef'] > abs_mean_filter].copy()\n",
    "        elif topN is not None:\n",
    "            temp = extract_gene_set(df)\n",
    "            n_total_pre_top = n_total = len(temp)\n",
    "            df = df.sort_values(by='abs_mean_coef', ascending=False).iloc[:topN,:].copy()\n",
    "        _gene_set = extract_gene_set(df)\n",
    "        _gene_set = set([s + \"__CNV\" for s in _gene_set])      \n",
    "        features_sets[key] = _gene_set\n",
    "        n_final = len(features_sets[key])\n",
    "        n_unique = df.shape[0]\n",
    "        \n",
    "    if n_total_pre_filt is not None:\n",
    "        logger.info(\n",
    "            str(n_unique)+' unique out of '+str(n_final)+' filtered out of '\n",
    "            +str(n_total)+' total features from '+key)\n",
    "    elif n_total_pre_top is not None:\n",
    "        logger.info(\n",
    "            'top'+str(topN)+': '+str(n_unique)+' unique out of '+str(n_final)+' filtered out of '\n",
    "            +str(n_total)+' total features from '+key)\n",
    "    else:\n",
    "        logger.info(str(n_unique)+' unique out of '+str(n_final)+' total features from '+key)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venn diagrams to explain the functionality of the cell below:<br>\n",
    "U --> data uniq genes (genes w/o dupl + single copy duplicates genes) <br>\n",
    "D --> the rest of the duplicates genes copies<br>\n",
    "fs --> a single features set<br>\n",
    "IU --> the features that exist in the U set<br>\n",
    "ID --> the features that exist in the D set<br>\n",
    "NI --> the features that do NOT exist in neither set<br>\n",
    "IDa --> the features that exist in the ID set and are not represented in the IU set<br>\n",
    "IDb --> the features that exist in the ID set and are already represented in the IU set<br>\n",
    "_ID = IDa + IDb_<br>\n",
    "U_IDa --> the features that exist in the U set (but not in the IU set) and represent the IDa features<br>\n",
    "**fs in data_uniq = IU + U_IDa**<br>\n",
    "<img src=\"./files/venn_legend.jpg?1\" alt=\"drawing\" style=\"float:left\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# U: all_data_genes_uniq\n",
    "# D: all_dupl_set.difference(all_data_genes_uniq)\n",
    "# fs: features_sets[key]\n",
    "new_features_sets = {}\n",
    "\n",
    "for key in features_sets:\n",
    "    if genepanel_key_name in key:\n",
    "        U_set = all_var_data_genes\n",
    "        D_set = set()\n",
    "    else:\n",
    "        U_set = all_cnv_data_genes_uniq\n",
    "        D_set = all_dupl_set.difference(all_cnv_data_genes_uniq)\n",
    "            \n",
    "    fs = features_sets[key]\n",
    "    _fs_original_size = len(fs)\n",
    "    print(key+' feature set :')\n",
    "    print('--- originally ---')\n",
    "    print(' original total size: '+str(_fs_original_size))\n",
    "    IU_set = fs.intersection(U_set)\n",
    "    _IU_size = len(IU_set)\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "\n",
    "    ID_set = (fs.difference(IU_set)).intersection(D_set)\n",
    "    _ID_size = len(ID_set)\n",
    "    print(' ID_set: '+str(_ID_size))\n",
    "\n",
    "    NI_set = (fs.difference(IU_set)).difference(ID_set)\n",
    "    _NI_size =len(NI_set)\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    U_IDa_set = set()\n",
    "    IDa_set = set()\n",
    "    IDb_set = set()\n",
    "    IDc_set = set()\n",
    "    done = False\n",
    "    temp_set = ID_set.copy()\n",
    "    while temp_set and not done:\n",
    "        for ud, dl in dupldict.items():\n",
    "            _IDx = set(dl).intersection(temp_set)\n",
    "            if _IDx:\n",
    "                temp_set = temp_set.difference(_IDx)\n",
    "                if ud not in IU_set:\n",
    "                    U_IDa_set.add(ud)\n",
    "                    IDa_set.update(_IDx)\n",
    "                else:\n",
    "                    IDb_set.update(_IDx) \n",
    "        done = True\n",
    "\n",
    "    fs_in_data_uniq = set.union(IU_set, U_IDa_set)\n",
    "    _fs_in_data_uniq_size = len(fs_in_data_uniq)\n",
    "\n",
    "    ########################################\n",
    "    new_features_sets[key] = fs_in_data_uniq\n",
    "    ########################################\n",
    "    \n",
    "    print('--- finally ---')\n",
    "    print(' features in data uniq : '+str(_fs_in_data_uniq_size))\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "    print('   U_IDa_set: '+str(len(U_IDa_set)))\n",
    "    print(' ID_set: '+str(len(ID_set)))\n",
    "    print('   IDa_set: '+str(len(IDa_set)))\n",
    "    print('   IDb_set: '+str(len(IDb_set)))\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    if ID_set != set.union(IDa_set, IDb_set):\n",
    "        print(\n",
    "            'ERROR: something went wrong, ID_set != IDa_set + IDb_set, for feature set: '+key\n",
    "        )\n",
    "        break\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the feature set in the current Dataset in respect to how it was originally from the data it was selected from<br>\n",
    "<img src=\"./files/venn_legend_2.jpg?1\" alt=\"drawing\" style=\"float:left\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_sets.update({\n",
    "    key: set.union(\n",
    "        *[new_features_sets[x] for x in feature_combinations[key]]\n",
    "    ) for key in feature_combinations\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sets.update({\n",
    "    key: set.union(\n",
    "        *[features_sets[x] for x in feature_combinations[key]]\n",
    "    ) for key in feature_combinations\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for every feature set in the new_features_sets (even the combinations)\n",
    "# that is corresponding to data_uniq, \n",
    "# save a table with the feature names as index\n",
    "# and their duplicates, from dupldict in another column\n",
    "# include also other columns, like chr, start and end from the gene_info table\n",
    "# save also the positions of these duplicate genes\n",
    "# finally save separately the info on the remaining features, the ones not in the data\n",
    "\n",
    "for key in new_features_sets.keys():\n",
    "    print(key)\n",
    "    fset = list(new_features_sets[key])\n",
    "    # a table with the feature names as index\n",
    "    feature_table = pd.DataFrame(index=fset)\n",
    "    # the duplicates, from dupldict\n",
    "    feature_table['dupl_features'] = \\\n",
    "        feature_table.index.map(dupldict).values\n",
    "    # include other columns, like chr, start and end from the gene_info table\n",
    "    feature_table = pd.concat([feature_table, genes_info.set_index(gene_id_col)], axis=1, join='inner')\n",
    "\n",
    "    # save the chr and positions of the duplicate genes\n",
    "    for agene in feature_table.index:\n",
    "        if agene in dupldict.keys():\n",
    "            l = [agene]\n",
    "            l.extend(dupldict[agene])\n",
    "            feature_table.loc[agene, 'aggChrGene'] = str(natsorted(\n",
    "                        genes_info.set_index(\n",
    "                            gene_id_col).loc[l].reset_index().groupby(\n",
    "                                by=['chr'])['gene'].apply(\n",
    "                                    lambda x: list(np.unique(np.append([], x)))\n",
    "                                    ).reset_index().values.tolist()))\n",
    "            aggPos = \\\n",
    "                genes_info.set_index(gene_id_col).loc[l].groupby(\n",
    "                    by=['chr']).agg(\n",
    "                        {'start': min, 'end': max}\n",
    "                        ).reset_index().astype(str).apply(\n",
    "                            lambda x: ':'.join(x), axis=1).values\n",
    "            feature_table.loc[agene, 'aggPos'] = np.apply_along_axis(\n",
    "                        lambda x: '__'.join(x), 0, natsorted(aggPos))\n",
    "\n",
    "    # get separately the info on the remaining features, the ones not in the data\n",
    "    remaining_features = pd.DataFrame(index=sorted(list(features_sets[key].difference(new_features_sets[key]))))\n",
    "    # info on chr, start, end etc. from the gene_info table\n",
    "    remaining_features = remaining_features.join(genes_info.set_index(gene_id_col), how='left')\n",
    "    index_name = remaining_features.index.name = 'gene'\n",
    "    # remove any __XX..X suffix to be able to cross-reference with the original features_dict\n",
    "    remaining_features['cleanName'] = \\\n",
    "                remaining_features.reset_index()[index_name]\\\n",
    "                .str.split('__', expand=True)[0].values\n",
    "\n",
    "    if key in features_dict:\n",
    "        # cross-reference with the original features_dict\n",
    "        df = features_dict[key].copy()\n",
    "        if 'cleanName' not in df.columns:\n",
    "            index_name = df.index.name = 'dummy'\n",
    "            df['cleanName'] = \\\n",
    "                df.reset_index()[index_name]\\\n",
    "                .str.split('__', expand=True)[0].values\n",
    "            \n",
    "        for row in df.index:\n",
    "            # for each row add the remaining features that match it\n",
    "            if df.loc[row,'dupl_genes'] is not np.nan:\n",
    "                original_dupl_gene_set = set([df.loc[row,'cleanName']]).union(eval(df.loc[row,'dupl_genes']))\n",
    "                remaining_gene_set = set(remaining_features['cleanName'].values)\n",
    "                row_dupl_gene_set = remaining_gene_set.intersection(original_dupl_gene_set)\n",
    "                df.loc[row,'remaining_dupl_genes'] = str(list(row_dupl_gene_set))\n",
    "\n",
    "        # if there are remaining features that do not match any row \n",
    "        #(although this should probably never happen)\n",
    "        # then add them as new rows \n",
    "        # and add info on chr, start, end etc. from the gene_info table\n",
    "        original_dupl_gene_set = extract_gene_set(features_dict[key])\n",
    "        new_dupl_gene_set = extract_gene_set(df)\n",
    "        remaining_uniq_gene_set = original_dupl_gene_set.difference(new_dupl_gene_set)\n",
    "        if remaining_uniq_gene_set:\n",
    "            df = pd.concat(\n",
    "                [df, remaining_features.loc[list(remaining_uniq_gene_set),:]], \n",
    "                axis=0, join='outer', sort=False\n",
    "            )\n",
    "\n",
    "        remaining_features_with_info = df.copy()\n",
    "    else:\n",
    "        remaining_features_with_info = remaining_features\n",
    "\n",
    "    # save as tab-delimited csv file\n",
    "    fname = 'features_'+key+'_in_data.csv'\n",
    "    fpath = os.path.join(output_directory, fname)\n",
    "    logger.info(\"-save combined features in :\\n\"+fpath)\n",
    "    feature_table.to_csv(\n",
    "        fpath, sep='\\t', header=True, index=True)\n",
    "    \n",
    "    fname = 'features_'+key+'_NOT_in_data.csv'\n",
    "    fpath = os.path.join(output_directory, fname)\n",
    "    logger.info(\"-save combined features in :\\n\"+fpath)\n",
    "    remaining_features_with_info.to_csv(\n",
    "        fpath, sep='\\t', header=True, index=True)\n",
    "\n",
    "    # save also as excel file\n",
    "    fname = 'features_'+key+'.xlsx'\n",
    "    fpath = os.path.join(output_directory, fname)\n",
    "    logger.info('-save csv file as excel too')\n",
    "    writer = pd.ExcelWriter(fpath)\n",
    "    feature_table.to_excel(writer, sheet_name='featuresInData')\n",
    "    remaining_features_with_info.to_excel(writer, sheet_name='featuresNOTInData')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs_fprs = {}\n",
    "fs_tprs = {}\n",
    "fs_aucs = {}\n",
    "for key in new_features_sets:\n",
    "    mixed_plot_kwargs['x_ut'] = 100\n",
    "    \n",
    "    fset = natsorted(list(new_features_sets[key]))\n",
    "    X_train = data_train.loc[:,fset].copy()\n",
    "    X_test = data_test.loc[:,fset].copy()\n",
    "    \n",
    "    #  Plot Heatmap of features data w/o duplicates\n",
    "    plot_data_heatmap(\n",
    "        X_train, y_train, None, None, **mixed_plot_kwargs\n",
    "    )\n",
    "    plt.title(key+' features in train data w/o duplicates: '+str(len(fset))+' features')\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"heatmap_\"+key+\"_fs_train_data_uniq\", img_ext=img_ext)\n",
    "    \n",
    "    #  Plot Heatmap of features w/o duplicates\n",
    "    plot_data_heatmap(\n",
    "        X_test, y_test, None, None, **mixed_plot_kwargs\n",
    "    )\n",
    "    plt.title(key+' features in test data w/o duplicates: '+str(len(fset))+' features')\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"heatmap_\"+key+\"_fs_test_data_uniq\", img_ext=img_ext)\n",
    "    \n",
    "\n",
    "    # train model\n",
    "    model, all_coefs, y_train_predictions, y_train_scores, fprs, tprs, interps, aucs = \\\n",
    "        _run_classification(\n",
    "            X_train, y_train, **classification_args)\n",
    "\n",
    "    # plot_prediction_counts_per_class\n",
    "    plot_prediction_counts_per_class(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"count_predictions_per_class\", img_ext=img_ext)\n",
    "\n",
    "    # compute_and_plot_confusion_matrices\n",
    "    plt1, plt2 = compute_and_plot_confusion_matrices(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix\", img_ext=img_ext, plt_obj=plt1)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix_normalized\", img_ext=img_ext, plt_obj=plt2)\n",
    "\n",
    "    # plot_roc_with_std_for_one_model\n",
    "    n_splits = classification_args[\"n_splits\"]\n",
    "    plot_roc_with_std_for_one_model(n_splits, fprs, tprs, interps, aucs, figsize=(10,10), model_name=key)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"train_crossval_roc_curves_\"+key, img_ext=img_ext)\n",
    "\n",
    "    # Test the model\n",
    "    y_test_score = model.score(X_test, y_test)\n",
    "    y_test_predictions = model.predict(X_test)\n",
    "    y_test_predictions = pd.Series(y_test_predictions, index=X_test.index)\n",
    "    y_test_predictions.name = 'test_predictions'\n",
    "\n",
    "    # Plot scatter plot of scores\n",
    "    plot_scatter_scores(y_train_scores, y_test_score)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"scatter_scores\", img_ext=img_ext)\n",
    "    \n",
    "    # prepare for the ROC curves on each feature set\n",
    "    y_proba = model.decision_function(X_test)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    fs_fprs[key] = fpr\n",
    "    fs_tprs[key] = tpr\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fs_aucs[key] = roc_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_models = list(new_features_sets.keys())\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10), \n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models})\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_all_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_models = ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx', 'CNVc1c2', 'CNVcAll']\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10),\n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models}\n",
    ")\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_some_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aucs = pd.DataFrame.from_dict(fs_aucs, orient='index', columns=['AUC'])\n",
    "choose_models = all_aucs.sort_values(by='AUC', ascending=False).iloc[:5].index.values\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10),\n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models}\n",
    ")\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_best_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key\n",
    "\n",
    "# roc_auc\n",
    "\n",
    "# y_proba\n",
    "\n",
    "# softmax = np.exp(y_proba)/np.sum(np.exp(y_proba))\n",
    "\n",
    "# softmax\n",
    "\n",
    "# fpr_sm, tpr_sm, thresholds_sm = roc_curve(y_test, softmax)\n",
    "\n",
    "# roc_auc_sm = auc(fpr_sm, tpr_sm)\n",
    "\n",
    "# roc_auc_sm\n",
    "\n",
    "# clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "# clf.fit(X_test, y_test)\n",
    "# y_proba_new = clf.predict_proba(X_test)\n",
    "\n",
    "# y_proba_new\n",
    "\n",
    "# fpr_new, tpr_new, thresholds_new = roc_curve(y_test, y_proba_new[:,1])\n",
    "\n",
    "# roc_auc_new = auc(fpr_new, tpr_new)\n",
    "\n",
    "# roc_auc_new\n",
    "\n",
    "# key = 'genepanel'\n",
    "# saveReport = False\n",
    "\n",
    "\n",
    "# fset = list(new_features_sets[key])\n",
    "# X_train = data_train.loc[:,fset].copy()\n",
    "# X_test = data_test.loc[:,fset].copy()\n",
    "\n",
    "# # train model\n",
    "# model, all_coefs, y_train_predictions, y_train_scores, fprs, tprs, interps, aucs = \\\n",
    "#     _run_classification(\n",
    "#         X_train, y_train, **classification_args)\n",
    "\n",
    "# # Test the model\n",
    "# y_test_score = model.score(X_test, y_test)\n",
    "# y_test_predictions = model.predict(X_test)\n",
    "# y_test_predictions = pd.Series(y_test_predictions, index=X_test.index)\n",
    "# y_test_predictions.name = 'test_predictions'\n",
    "\n",
    "\n",
    "# # prepare for the ROC curves on each feature set\n",
    "\n",
    "# y_proba = model.decision_function(X_test)\n",
    "# # Compute ROC curve and area the curve\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "# fs_fprs[key] = fpr\n",
    "# fs_tprs[key] = tpr\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# fs_aucs[key] = roc_auc\n",
    "\n",
    "# roc_auc\n",
    "\n",
    "# y_proba\n",
    "\n",
    "# softmax = np.exp(y_proba)/np.sum(np.exp(y_proba))\n",
    "# softmax\n",
    "\n",
    "# fpr_sm, tpr_sm, thresholds_sm = roc_curve(y_test, softmax)\n",
    "# roc_auc_sm = auc(fpr_sm, tpr_sm)\n",
    "# roc_auc_sm\n",
    "\n",
    "# clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "# clf.fit(X_test, y_test)\n",
    "# y_proba_clf = clf.predict_proba(X_test)\n",
    "# fpr_clf, tpr_clf, thresholds_clf = roc_curve(y_test, y_proba_clf[:, 1])\n",
    "# roc_auc_clf = auc(fpr_clf, tpr_clf)\n",
    "# roc_auc_clf\n",
    "\n",
    "# y_proba_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
