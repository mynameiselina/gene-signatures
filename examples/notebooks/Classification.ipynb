{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params\n",
    "DEBUG = True\n",
    "saveReport = True\n",
    "toPrint = True\n",
    "reportName = 'notebook'\n",
    "txt_label = \"Classification of integrated c1 and c2 CNVs samples\"\n",
    "\n",
    "\n",
    "# train test split params\n",
    "split_train_size = 40\n",
    "split_random_state = 0\n",
    "\n",
    "# classification params\n",
    "classification_args = {\n",
    "    \"n_splits\": 10,\n",
    "    \"random_state\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting params\n",
    "\n",
    "with_swarm = False\n",
    "highRes = False\n",
    "if highRes:\n",
    "    img_ext = '.pdf'\n",
    "else:\n",
    "    img_ext = '.png'\n",
    "\n",
    "\n",
    "cnv_plot_kwargs = {\n",
    "    \"vmin\": -2,\n",
    "    \"vmax\": +2,\n",
    "    \"mincol\": \"red\",\n",
    "    \"midcol\": \"white\",\n",
    "    \"maxcol\": \"blue\",\n",
    "    \"function_dict\": None\n",
    "}\n",
    "\n",
    "var_plot_kwargs = {\n",
    "    \"vmin\": 0,\n",
    "    \"vmax\": 4,\n",
    "    \"mincol\": \"white\",\n",
    "    \"midcol\": \"orange\",\n",
    "    \"maxcol\": \"red\",\n",
    "    \"function_dict\": {\n",
    "        \"no mutation\": 0,\n",
    "        \"missense\": 1,\n",
    "        \"nonframeshiftIndel\": 2,\n",
    "        \"nonsense\": 3,\n",
    "        \"frameshiftIndel\": 4\n",
    "    }\n",
    "}\n",
    "\n",
    "mixed_plot_kwargs = {\n",
    "    \"vmin\": -4,\n",
    "    \"vmax\": +4,\n",
    "    \"mincol\": \"red\",\n",
    "    \"midcol\": \"white\",\n",
    "    \"maxcol\": \"purple\",\n",
    "    \"function_dict\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file\n",
    "cnv_data_fpath = \"output/headneck/integrate_cohorts/c1c2/CNV_mapped_filt/integrated_data.csv\"\n",
    "var_data_fpath = \"output/headneck/integrate_cohorts/c1c2/genepanel/integrated_data.csv\"\n",
    "\n",
    "# sample_info file\n",
    "sample_info_fpath = \"output/headneck/integrate_cohorts/c1c2/integrated_sample_info.csv\"\n",
    "sample_class_column = \"Relapsed\"\n",
    "class_labels = [\"relapsed\",\"NOTrelapsed\"]\n",
    "class_values = [1,0]\n",
    "\n",
    "# genes_info file\n",
    "genes_info_fpath = \"output/headneck/setup_c1_oncoscan_byNexus/genes_info.csv\"\n",
    "chr_col = 'chr_int'\n",
    "gene_id_col = 'gene'\n",
    "\n",
    "# output dir\n",
    "output_directory = \"output/headneck/classification/\"+reportName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments to load the sample_info file\n",
    "sample_info_read_csv_kwargs = {\n",
    "    \"sep\": \"\\t\",\n",
    "    \"header\": 0,\n",
    "    \"col_as_index\":\"patientID\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "genepanel_fpath = \"output/headneck/setup_c1_genepanel/process_select_primary/data_processed.csv\"\n",
    "genepanel_key_name = 'genepanel'\n",
    "\n",
    "feature_dirs = ['c1_prmr_OncFltNxEx', 'c2_ExcvFltNxEx', 'c1_prmr_mapped_c2_CnvNxEx', 'c1_prmr_mapped_c2_Cnv', 'c1_prmr_mapped_c2_CnvMixedNxEx']\n",
    "feature_key_names = ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx', 'c3_Cnv', 'c3_CnvMixedNxEx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from omics_processing.io import (\n",
    "    set_directory, load_clinical\n",
    ")\n",
    "from omics_processing.remove_duplicates import (\n",
    "    remove_andSave_duplicates\n",
    ")\n",
    "from gene_signatures.core import (\n",
    "    custom_div_cmap,\n",
    "    get_chr_ticks,\n",
    "    choose_samples,\n",
    "    parse_arg_type,\n",
    "    boxplot,\n",
    "    set_heatmap_size,\n",
    "    set_cbar_ticks,\n",
    "    edit_names_with_duplicates,\n",
    "    plot_confusion_matrix,\n",
    "    define_plot_args,\n",
    "    plot_scatter_scores,\n",
    "    plot_roc_with_std_for_one_model,\n",
    "    plot_roc_for_many_models,\n",
    "    compute_and_plot_confusion_matrices,\n",
    "    plot_prediction_counts_per_class,\n",
    "    plot_data_heatmap,\n",
    "    extract_gene_set,\n",
    "    save_image,\n",
    "    check_path_integrity\n",
    ")\n",
    "\n",
    "# basic imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from natsort import natsorted, index_natsorted\n",
    "import math\n",
    "import logging\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from distutils.util import strtobool\n",
    "from scipy.stats import binom_test\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "# plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "script_path = os.getcwd()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_classification(\n",
    "        dat, dat_target, random_state=None, n_splits=10):\n",
    "\n",
    "    min_class_count = np.unique(dat_target, return_counts=True)[1].min()\n",
    "    if n_splits is not None:\n",
    "        if (n_splits > dat.shape[0]) or (n_splits > min_class_count):\n",
    "            n_splits = min_class_count\n",
    "    if random_state is not None:\n",
    "        random_state = parse_arg_type(random_state, int)\n",
    "    else:\n",
    "        random_state = 0\n",
    "    logger.info(\n",
    "        \"model: svm.LinearSVC with l2 penalty, squared_hinge loss \" +\n",
    "        \"and random_state: \"+str(random_state)\n",
    "    )\n",
    "    model = svm.LinearSVC(\n",
    "        penalty='l2', C=1, random_state=random_state,\n",
    "        loss='squared_hinge', dual=False\n",
    "    )\n",
    "\n",
    "    logger.info(\"Running classification...\")\n",
    "    dat = dat.copy()\n",
    "    dat_target = dat_target.copy()\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    k_fold = StratifiedKFold(n_splits=n_splits)\n",
    "    cross_val_scores = []\n",
    "    all_coefs = np.zeros((n_splits, dat.shape[1]))\n",
    "    y_train_predictions = pd.Series(index=y.index)\n",
    "    y_train_predictions.name = \"train_predictions\"\n",
    "    \n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    interps = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    split_i = 0\n",
    "    for train_indices, test_indices in k_fold.split(X, y):\n",
    "        X_train = dat.iloc[train_indices]\n",
    "        y_train = dat_target.iloc[train_indices]\n",
    "        \n",
    "        X_crossval = dat.iloc[test_indices]\n",
    "        y_crossval = dat_target.iloc[test_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        all_coefs[split_i:split_i+1, :] = model.coef_[0]\n",
    "        cross_val_scores.append(model.score(X_crossval, y_crossval))\n",
    "        y_train_predictions.iloc[test_indices] = model.predict(X_crossval)\n",
    "        \n",
    "        \n",
    "#         y_proba = model.decision_function(X_crossval)\n",
    "        clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "        clf.fit(X_crossval, y_crossval)\n",
    "        y_proba = clf.predict_proba(X_crossval)\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_crossval, y_proba[:, 1])\n",
    "#         fpr, tpr, thresholds = roc_curve(y_crossval, y_proba)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        interps.append(interp(mean_fpr, fpr, tpr))\n",
    "        interps[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        split_i += 1\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    model.fit(X, y)\n",
    "\n",
    "    all_coefs = pd.DataFrame(all_coefs, columns=dat.columns.values)\n",
    "\n",
    "    return model, all_coefs, y_train_predictions, cross_val_scores, fprs, tprs, interps, aucs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly set file paths\n",
    "try:\n",
    "    os.path.exists(MainDataDir)\n",
    "except:\n",
    "    MainDataDir = os.path.join(script_path, '..','..', 'data')\n",
    "    logger.debug(\"set MainDataDir:\\n\"+MainDataDir)\n",
    "\n",
    "# data output\n",
    "output_directory = check_path_integrity(output_directory, rootDir=MainDataDir, name=\"output\", force=True)\n",
    "\n",
    "if DEBUG:\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnv data input\n",
    "cnv_data_fpath = check_path_integrity(cnv_data_fpath, rootDir=MainDataDir, name=\"cnv data\")\n",
    "\n",
    "# genepanel data input\n",
    "var_data_fpath = check_path_integrity(var_data_fpath, rootDir=MainDataDir, name=\"var data\")\n",
    "\n",
    "# sample info input\n",
    "sample_info_fpath = check_path_integrity(sample_info_fpath, rootDir=MainDataDir, name=\"sample_info\")\n",
    "\n",
    "# gene info input\n",
    "genes_info_fpath = check_path_integrity(genes_info_fpath, rootDir=MainDataDir, name=\"gene_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpaths_dict\n",
    "fpaths_dict = {}\n",
    "fpaths_dict[genepanel_key_name] = check_path_integrity(genepanel_fpath, rootDir=MainDataDir, name=\"genepanel features\")\n",
    "\n",
    "for _f, _k in zip(feature_dirs, feature_key_names):\n",
    "    fpath = \"output/headneck/feature_selection/\"+_f+\"/featsel_results.csv\"\n",
    "    fpaths_dict[_k] = check_path_integrity(fpath, rootDir=MainDataDir, name=_k+\" features\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cnv data\n",
    "cnv_data = pd.read_csv(cnv_data_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded cnv data file with shape: '+str(cnv_data.shape))\n",
    "\n",
    "cnv_data.columns += \"__CNV\"\n",
    "\n",
    "cnv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load genepanel data\n",
    "var_data = pd.read_csv(var_data_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded var data file with shape: '+str(var_data.shape))\n",
    "\n",
    "var_data.columns += \"__VAR\"\n",
    "\n",
    "var_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load info table of samples\n",
    "sample_info = load_clinical(\n",
    "    sample_info_fpath, **sample_info_read_csv_kwargs)\n",
    "logger.info('loaded sample_info file with shape: '+str(sample_info.shape))\n",
    "\n",
    "sample_info = sample_info.loc[cnv_data.index,:]\n",
    "logger.info('keeping part of sample_infowith shape: '+str(sample_info.shape))\n",
    "\n",
    "sample_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info table of genes\n",
    "genes_info = pd.read_csv(genes_info_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded gene_info file with shape: '+str(genes_info.shape))\n",
    "\n",
    "genes_info[gene_id_col] += \"__CNV\"\n",
    "\n",
    "genes_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the ground truth\n",
    "ground_truth = sample_info.loc[cnv_data.index, sample_class_column]\n",
    "\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plots\n",
    "class_labels = np.array(class_labels)\n",
    "class_values = np.array(class_values)\n",
    "\n",
    "adict = define_plot_args(**cnv_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "cnv_plot_kwargs.update(adict)\n",
    "\n",
    "adict = define_plot_args(**var_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "var_plot_kwargs.update(adict)\n",
    "\n",
    "adict = define_plot_args(**mixed_plot_kwargs)\n",
    "# update cnv_plot_kwargs with adict\n",
    "mixed_plot_kwargs.update(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of genepanel_data\n",
    "plot_data_heatmap(\n",
    "    var_data, ground_truth, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var data: '+str(var_data.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of cnv_data w/ duplicates\n",
    "xlabels, xpos = get_chr_ticks(\n",
    "    genes_info, cnv_data, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    cnv_data, ground_truth, xlabels, xpos, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv data: '+str(cnv_data.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all zero columns!\n",
    "orphancols = np.where(abs(cnv_data).sum(axis=0) == 0)[0]\n",
    "if len(orphancols) > 0:\n",
    "    logger.warning('removing '+str(len(orphancols))+' genes from cnv data with zero columns!')\n",
    "    cols2drop = cnv_data.columns.values[orphancols]\n",
    "    cnv_data = cnv_data.drop(cols2drop, axis=1).copy()\n",
    "\n",
    "# REMOVE DUPLICATES!!!!\n",
    "cnv_data_uniq, dupldict, wo_dupl_set, all_dupl_set = remove_andSave_duplicates(\n",
    "    cnv_data, to_compute_euclidean_distances=True,\n",
    "    to_save_euclidean_distances=True, to_save_output=True,\n",
    "    output_filename='cnv_data_wo_duplicates',\n",
    "    output_directory=output_directory\n",
    ")\n",
    "single_dupl_set = set(dupldict.keys())\n",
    "\n",
    "_countA = len(set.union(single_dupl_set, wo_dupl_set))\n",
    "_countB = cnv_data_uniq.shape[1]\n",
    "if not _countA == _countB:\n",
    "    print(\n",
    "        'ERROR: inconsistencies in the final uniq gene count!\\n'+\n",
    "        str(_countA)+' genes that should be in the uniq dataset VS. '+\n",
    "        str(_countB)+' genes that are'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of cnv data w/o duplicates\n",
    "xlabels_uniq, xpos_uniq = get_chr_ticks(\n",
    "    genes_info, cnv_data_uniq, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    cnv_data_uniq, ground_truth, xlabels_uniq, xpos_uniq, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv data w/o duplicates: '+str(cnv_data_uniq.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_uniq\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine var and cnv features\n",
    "data_uniq = pd.concat([cnv_data_uniq, var_data], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of mixed data w/o duplicates\n",
    "plot_data_heatmap(\n",
    "    data_uniq, ground_truth, None, None, **mixed_plot_kwargs\n",
    ")\n",
    "plt.title('mixed data w/o duplicates: '+str(data_uniq.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_mixed_data_uniq\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train-test ONCE!\n",
    "stratify_by = pd.concat([ground_truth, sample_info['dataset']], axis=1, sort=False)\n",
    "stratify_by = stratify_by.loc[ground_truth.index]\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data_uniq, ground_truth,\n",
    "    train_size=split_train_size,\n",
    "    test_size=None,\n",
    "    random_state=split_random_state,\n",
    "    stratify=stratify_by\n",
    ")\n",
    "\n",
    "cnv_data_train = cnv_data.loc[data_train.index,:].copy()\n",
    "cnv_data_test = cnv_data.loc[data_test.index,:].copy()\n",
    "\n",
    "\n",
    "var_data_train = var_data.loc[data_train.index,:].copy()\n",
    "var_data_test = var_data.loc[data_test.index,:].copy()\n",
    "\n",
    "stratify_by.hist()\n",
    "plt.suptitle('all '+str(ground_truth.shape[0])+' samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_all\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[cnv_data_train.index].hist()\n",
    "plt.suptitle(str(y_train.shape[0])+' train samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_train\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[cnv_data_test.index].hist()\n",
    "plt.suptitle(str(y_test.shape[0])+' test samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_test\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels_train, xpos_train = get_chr_ticks(\n",
    "    genes_info, cnv_data_train, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "xlabels_test, xpos_test = get_chr_ticks(\n",
    "    genes_info, cnv_data_test, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "#  Plot Heatmap of train cnv data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    cnv_data_train, y_train, xlabels_train, xpos_train, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv train data: '+str(cnv_data_train.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_train\", img_ext=img_ext)\n",
    "\n",
    "#  Plot Heatmap of test cnv data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    cnv_data_test, y_test, xlabels_test, xpos_test, **cnv_plot_kwargs\n",
    ")\n",
    "plt.title('cnv test data: '+str(cnv_data_test.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_cnv_data_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of train var data\n",
    "plot_data_heatmap(\n",
    "    var_data_train, y_train, None, None, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var train data: '+str(var_data_train.shape[1])+' genes')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data_train\", img_ext=img_ext)\n",
    "\n",
    "#  Plot Heatmap of test var data\n",
    "plot_data_heatmap(\n",
    "    var_data_test, y_test, None, None, **var_plot_kwargs\n",
    ")\n",
    "plt.title('var test data: '+str(var_data_test.shape[1])+' genes')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_var_data_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cnv_data_genes = set(cnv_data.columns.values)\n",
    "all_cnv_data_genes_uniq = set(cnv_data_uniq.columns.values)\n",
    "\n",
    "all_var_data_genes = set(var_data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {}\n",
    "features_sets = {}\n",
    "for key in fpaths_dict:\n",
    "    \n",
    "    df = pd.read_csv(fpaths_dict[key], sep='\\t', header=0, index_col=0)\n",
    "    \n",
    "    if genepanel_key_name in key:\n",
    "        df.columns += \"__VAR\"\n",
    "        features_sets[key] = set(df.columns.values)\n",
    "        n_total = len(features_sets[key])\n",
    "        n_unique = n_total\n",
    "    else:\n",
    "        features_dict[key] = df\n",
    "        _gene_set = extract_gene_set(df)\n",
    "        _gene_set = set([s + \"__CNV\" for s in _gene_set])      \n",
    "        features_sets[key] = _gene_set\n",
    "        n_total = len(features_sets[key])\n",
    "        n_unique = df.shape[0]\n",
    "        \n",
    "    logger.info(str(n_unique)+' unique out of '+str(n_total)+' total features from '+key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venn diagrams to explain the functionality of the cell below:<br>\n",
    "U --> data uniq genes (genes w/o dupl + single copy duplicates genes) <br>\n",
    "D --> the rest of the duplicates genes copies<br>\n",
    "fs --> a single features set<br>\n",
    "IU --> the features that exist in the U set<br>\n",
    "ID --> the features that exist in the D set<br>\n",
    "NI --> the features that do NOT exist in neither set<br>\n",
    "IDa --> the features that exist in the ID set and are not represented in the IU set<br>\n",
    "IDb --> the features that exist in the ID set and are already represented in the IU set<br>\n",
    "_ID = IDa + IDb_<br>\n",
    "U_IDa --> the features that exist in the U set (but not in the IU set) and represent the IDa features<br>\n",
    "**fs in data_uniq = IU + U_IDa**<br>\n",
    "<img src=\"./files/venn_legend.jpg?1\" alt=\"drawing\" style=\"float:left\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# U: all_data_genes_uniq\n",
    "# D: all_dupl_set.difference(all_data_genes_uniq)\n",
    "# fs: features_sets[key]\n",
    "new_features_sets = {}\n",
    "\n",
    "for key in features_sets:\n",
    "    if genepanel_key_name in key:\n",
    "        U_set = all_var_data_genes\n",
    "        D_set = set()\n",
    "    else:\n",
    "        U_set = all_cnv_data_genes_uniq\n",
    "        D_set = all_dupl_set.difference(all_cnv_data_genes_uniq)\n",
    "            \n",
    "    fs = features_sets[key]\n",
    "    _fs_original_size = len(fs)\n",
    "    print(key+' feature set :')\n",
    "    print('--- originally ---')\n",
    "    print(' original total size: '+str(_fs_original_size))\n",
    "    IU_set = fs.intersection(U_set)\n",
    "    _IU_size = len(IU_set)\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "\n",
    "    ID_set = (fs.difference(IU_set)).intersection(D_set)\n",
    "    _ID_size = len(ID_set)\n",
    "    print(' ID_set: '+str(_ID_size))\n",
    "\n",
    "    NI_set = (fs.difference(IU_set)).difference(ID_set)\n",
    "    _NI_size =len(NI_set)\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    U_IDa_set = set()\n",
    "    IDa_set = set()\n",
    "    IDb_set = set()\n",
    "    IDc_set = set()\n",
    "    done = False\n",
    "    temp_set = ID_set.copy()\n",
    "    while temp_set and not done:\n",
    "        for ud, dl in dupldict.items():\n",
    "            _IDx = set(dl).intersection(temp_set)\n",
    "            if _IDx:\n",
    "                temp_set = temp_set.difference(_IDx)\n",
    "                if ud not in IU_set:\n",
    "                    U_IDa_set.add(ud)\n",
    "                    IDa_set.update(_IDx)\n",
    "                else:\n",
    "                    IDb_set.update(_IDx) \n",
    "        done = True\n",
    "\n",
    "    fs_in_data_uniq = set.union(IU_set, U_IDa_set)\n",
    "    _fs_in_data_uniq_size = len(fs_in_data_uniq)\n",
    "\n",
    "    ########################################\n",
    "    new_features_sets[key] = fs_in_data_uniq\n",
    "    ########################################\n",
    "    \n",
    "    print('--- finally ---')\n",
    "    print(' features in data uniq : '+str(_fs_in_data_uniq_size))\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "    print('   U_IDa_set: '+str(len(U_IDa_set)))\n",
    "    print(' ID_set: '+str(len(ID_set)))\n",
    "    print('   IDa_set: '+str(len(IDa_set)))\n",
    "    print('   IDb_set: '+str(len(IDb_set)))\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    if ID_set != set.union(IDa_set, IDb_set):\n",
    "        print(\n",
    "            'ERROR: something went wrong, ID_set != IDa_set + IDb_set, for feature set: '+key\n",
    "        )\n",
    "        break\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose conbinations of features\n",
    "feature_combinations = {\n",
    "    'GnPnl_c1_OncFltNxEx': ['genepanel', 'c1_OncFltNxEx'], # 26 union\n",
    "    'GnPnl_c2_ExcvFltNxEx': ['genepanel', 'c2_ExcvFltNxEx'],  # 45 union\n",
    "    'GnPnl_c3_CnvNxEx': ['genepanel', 'c3_CnvNxEx'],  # 106 union\n",
    "#     'c3_CNVmix': ['c3_CnvNxEx', 'c3_Cnv', 'c3_CnvMixedNxEx'], # 1 common, 1337 union\n",
    "    'CNVc1c2': ['c1_OncFltNxEx', 'c2_ExcvFltNxEx'], # 45 union, 0 common\n",
    "    'GnPnl_CNVc1c2': ['genepanel', 'c1_OncFltNxEx', 'c2_ExcvFltNxEx'], # 58 union\n",
    "    'CNVcAll': ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx'], # 127 union\n",
    "    'GnPnl_CNVcAll': ['genepanel', 'c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx'] # 140 union\n",
    "}\n",
    "\n",
    "for key in feature_combinations:\n",
    "    new_features_sets[key] = set.union(*[new_features_sets[x] for x in feature_combinations[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_fprs = {}\n",
    "fs_tprs = {}\n",
    "fs_aucs = {}\n",
    "for key in new_features_sets:\n",
    "    fset = list(new_features_sets[key])\n",
    "    X_train = data_train.loc[:,fset].copy()\n",
    "    X_test = data_test.loc[:,fset].copy()\n",
    "\n",
    "    # train model\n",
    "    model, all_coefs, y_train_predictions, y_train_scores, fprs, tprs, interps, aucs = \\\n",
    "        _run_classification(\n",
    "            X_train, y_train, **classification_args)\n",
    "\n",
    "    # plot_prediction_counts_per_class\n",
    "    plot_prediction_counts_per_class(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"count_predictions_per_class\", img_ext=img_ext)\n",
    "\n",
    "    # compute_and_plot_confusion_matrices\n",
    "    plt1, plt2 = compute_and_plot_confusion_matrices(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix\", img_ext=img_ext, plt_obj=plt1)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix_normalized\", img_ext=img_ext, plt_obj=plt2)\n",
    "\n",
    "    # plot_roc_with_std_for_one_model\n",
    "    n_splits = classification_args[\"n_splits\"]\n",
    "    plot_roc_with_std_for_one_model(n_splits, fprs, tprs, interps, aucs, figsize=(10,10), model_name=key)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"train_crossval_roc_curves_\"+key, img_ext=img_ext)\n",
    "\n",
    "    # Test the model\n",
    "    y_test_score = model.score(X_test, y_test)\n",
    "    y_test_predictions = model.predict(X_test)\n",
    "    y_test_predictions = pd.Series(y_test_predictions, index=X_test.index)\n",
    "    y_test_predictions.name = 'test_predictions'\n",
    "\n",
    "    plot_scatter_scores(y_train_scores, y_test_score)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"scatter_scores\", img_ext=img_ext)\n",
    "    \n",
    "    # prepare for the ROC curves on each feature set\n",
    "    clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "    clf.fit(X_test, y_test)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "#     y_proba = model.decision_function(X_test)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "    fs_fprs[key] = fpr\n",
    "    fs_tprs[key] = tpr\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fs_aucs[key] = roc_auc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_models = list(new_features_sets.keys())\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10), \n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models})\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_all_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_models = ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx', 'CNVc1c2', 'CNVcAll']\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10),\n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models}\n",
    ")\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_some_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aucs = pd.DataFrame.from_dict(fs_aucs, orient='index', columns=['AUC'])\n",
    "choose_models = all_aucs.sort_values(by='AUC', ascending=False).iloc[:5].index.values\n",
    "plot_roc_for_many_models(\n",
    "    choose_models, fs_fprs, fs_tprs, fs_aucs, figsize=(10,10),\n",
    "    n_fs={key:len(new_features_sets[key]) for key in choose_models}\n",
    ")\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_best_models_roc_curves\", img_ext=img_ext)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
