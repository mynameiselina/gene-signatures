{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize params\n",
    "DEBUG = True\n",
    "saveReport = False\n",
    "toPrint = True\n",
    "reportName = 'notebook'\n",
    "txt_label = \"Classification of integrated c1 and c2 CNVs samples\"\n",
    "\n",
    "\n",
    "# train test split params\n",
    "split_train_size = 40\n",
    "split_random_state = 0\n",
    "\n",
    "# classification params\n",
    "classification_args = {\n",
    "    \"n_splits\": 10,\n",
    "    \"random_state\": 0\n",
    "}\n",
    "\n",
    "# plotting params\n",
    "function_dict = None\n",
    "with_swarm = False\n",
    "highRes = False\n",
    "if highRes:\n",
    "    img_ext = '.pdf'\n",
    "else:\n",
    "    img_ext = '.png'\n",
    "cmap_custom = None\n",
    "vmin, vmax = (-2, +2)\n",
    "plot_kwargs = {\n",
    "    \"mincol\":\"red\",\n",
    "    \"midcol\":\"white\",\n",
    "    \"maxcol\":\"blue\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file\n",
    "data_fpath = \"output/headneck/integrate_cohorts/c1c2/CNV_mapped_filt/integrated_data.csv\"\n",
    "\n",
    "# sample_info file\n",
    "sample_info_fpath = \"output/headneck/integrate_cohorts/c1c2/integrated_sample_info.csv\"\n",
    "sample_class_column = \"Relapsed\"\n",
    "class_labels = [\"relapsed\",\"NOTrelapsed\"]\n",
    "class_values = [1,0]\n",
    "\n",
    "# genes_info file\n",
    "genes_info_fpath = \"output/headneck/setup_c1_oncoscan_byNexus/genes_info.csv\"\n",
    "chr_col = 'chr_int'\n",
    "gene_id_col = 'gene'\n",
    "\n",
    "# output dir\n",
    "output_directory = \"output/headneck/classification/\"+reportName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments to load the sample_info file\n",
    "sample_info_read_csv_kwargs = {\n",
    "    \"sep\": \"\\t\",\n",
    "    \"header\": 0,\n",
    "    \"col_as_index\":\"patientID\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "genepanel_path = \"output/headneck/setup_c1_genepanel/process_select_primary/data_processed.csv\"\n",
    "_dirs = ['c1_prmr_OncFltNxEx', 'c2_ExcvFltNxEx', 'c1_prmr_mapped_c2_CnvNxEx', 'c1_prmr_mapped_c2_Cnv', 'c1_prmr_mapped_c2_CnvMixedNxEx']\n",
    "_key_names = ['c1_OncFltNxEx', 'c2_ExcvFltNxEx', 'c3_CnvNxEx', 'c3_Cnv', 'c3_CnvMixedNxEx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom imports\n",
    "from omics_processing.io import (\n",
    "    set_directory, load_clinical\n",
    ")\n",
    "from omics_processing.remove_duplicates import (\n",
    "    remove_andSave_duplicates\n",
    ")\n",
    "from gene_signatures.core import (\n",
    "    custom_div_cmap,\n",
    "    get_chr_ticks,\n",
    "    choose_samples,\n",
    "    parse_arg_type,\n",
    "    boxplot,\n",
    "    set_heatmap_size,\n",
    "    set_cbar_ticks,\n",
    "    edit_names_with_duplicates,\n",
    "    plot_confusion_matrix\n",
    ")\n",
    "\n",
    "# basic imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from natsort import natsorted, index_natsorted\n",
    "import math\n",
    "import logging\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from distutils.util import strtobool\n",
    "from scipy.stats import binom_test\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "# plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "\n",
    "script_path = os.getcwd()\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_path_integrity(f,rootDir=None, name=\"\", force=False):\n",
    "    if not os.path.exists(f):\n",
    "        f = os.path.join(*f.rsplit('/'))\n",
    "        f = os.path.join(rootDir, f)\n",
    "        if force:\n",
    "            f = set_directory(f)\n",
    "        logger.debug(\"set \"+name+\" fpath:\\n\"+f)\n",
    "    return f\n",
    "\n",
    "def save_image(saveReport=False, output_directory=\"\", img_name=\"figure\", img_ext=\".png\", plt_obj=None):\n",
    "    if plt_obj is None:\n",
    "        plt_obj = plt.gcf()\n",
    "    if saveReport:\n",
    "        logger.info('Save distplot')\n",
    "        plt_obj.savefig(os.path.join(\n",
    "            output_directory, 'Fig_'+img_name+img_ext),\n",
    "            transparent=True, bbox_inches='tight',\n",
    "            pad_inches=0.1, frameon=False)\n",
    "        plt_obj.close(\"all\")\n",
    "    else:\n",
    "        plt_obj.show()\n",
    "\n",
    "def extract_gene_set(df):\n",
    "    gene_set = set()\n",
    "    if 'dupl_genes' in df.columns:\n",
    "        dupl_col = df['dupl_genes']\n",
    "        dupl_set = set([\n",
    "            item for sublist in dupl_col \n",
    "            if isinstance(sublist, str) \n",
    "            for item in eval(sublist)\n",
    "        ])\n",
    "        gene_set = gene_set.union(set(dupl_set))\n",
    "\n",
    "        if 'cleanName' in df.columns:\n",
    "            gene_set = gene_set.union(set(df['cleanName'].values))\n",
    "    else:\n",
    "        gene_set = gene_set.union(set(df.index.values))\n",
    "        \n",
    "    return gene_set\n",
    "\n",
    "def plot_data_heatmap(\n",
    "    data, ground_truth, xlabel, xpos, \n",
    "    vmin, vmax, cmap_custom, custom_div_cmap_arg,\n",
    "    function_dict\n",
    "):\n",
    "    ground_truth_sorted = ground_truth.sort_values()\n",
    "    data_sorted = data.loc[ground_truth_sorted.index,:].copy()\n",
    "    try:\n",
    "        pat_labels_txt = ground_truth_sorted.astype(int).reset_index().values\n",
    "    except:\n",
    "        pat_labels_txt = ground_truth_sorted.reset_index().values\n",
    "\n",
    "    _figure_x_size, _figure_y_size, _show_gene_names, _ = \\\n",
    "        set_heatmap_size(data_sorted)\n",
    "    plt.figure(figsize=(_figure_x_size, _figure_y_size))\n",
    "    ax = sns.heatmap(data_sorted, vmin=vmin, vmax=vmax,\n",
    "                     yticklabels=pat_labels_txt, xticklabels=False,\n",
    "                     cmap=cmap_custom, cbar=False)\n",
    "    if (_show_gene_names and (\n",
    "            (xpos is None) or\n",
    "            (xlabel is None))):\n",
    "        plt.xticks(rotation=90)\n",
    "    elif (\n",
    "            (xpos is not None) and\n",
    "            (xlabel is not None)):\n",
    "        plt.xticks(xpos, xlabel, rotation=0)\n",
    "    plt.xlabel('chromosomes (the number is aligned at the end ' +\n",
    "               'of the chr region)')\n",
    "    plt.ylabel('samples')\n",
    "    cbar = ax.figure.colorbar(ax.collections[0])\n",
    "    set_cbar_ticks(cbar, function_dict, custom_div_cmap_arg)\n",
    "    \n",
    "def _run_classification(\n",
    "        dat, dat_target, random_state=None, n_splits=10):\n",
    "\n",
    "    min_class_count = np.unique(dat_target, return_counts=True)[1].min()\n",
    "    if n_splits is not None:\n",
    "        if (n_splits > dat.shape[0]) or (n_splits > min_class_count):\n",
    "            n_splits = min_class_count\n",
    "    if random_state is not None:\n",
    "        random_state = parse_arg_type(random_state, int)\n",
    "    else:\n",
    "        random_state = 0\n",
    "    logger.info(\n",
    "        \"model: svm.LinearSVC with l2 penalty, squared_hinge loss \" +\n",
    "        \"and random_state: \"+str(random_state)\n",
    "    )\n",
    "    model = svm.LinearSVC(\n",
    "        penalty='l2', C=1, random_state=random_state,\n",
    "        loss='squared_hinge', dual=False\n",
    "    )\n",
    "\n",
    "    logger.info(\"Running classification...\")\n",
    "    dat = dat.copy()\n",
    "    dat_target = dat_target.copy()\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    k_fold = StratifiedKFold(n_splits=n_splits)\n",
    "    cross_val_scores = []\n",
    "    all_coefs = np.zeros((n_splits, dat.shape[1]))\n",
    "    y_train_predictions = pd.Series(index=y.index)\n",
    "    y_train_predictions.name = \"train_predictions\"\n",
    "    \n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    interps = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    split_i = 0\n",
    "    for train_indices, test_indices in k_fold.split(X, y):\n",
    "        X_train = dat.iloc[train_indices]\n",
    "        y_train = dat_target.iloc[train_indices]\n",
    "        \n",
    "        X_crossval = dat.iloc[test_indices]\n",
    "        y_crossval = dat_target.iloc[test_indices]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        all_coefs[split_i:split_i+1, :] = model.coef_[0]\n",
    "        cross_val_scores.append(model.score(X_crossval, y_crossval))\n",
    "        y_train_predictions.iloc[test_indices] = model.predict(X_crossval)\n",
    "        \n",
    "        \n",
    "        clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "        clf.fit(X_crossval, y_crossval)\n",
    "        y_proba = clf.predict_proba(X_crossval)\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_crossval, y_proba[:, 1])\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        interps.append(interp(mean_fpr, fpr, tpr))\n",
    "        interps[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "\n",
    "        split_i += 1\n",
    "\n",
    "    X = dat\n",
    "    y = dat_target\n",
    "    model.fit(X, y)\n",
    "\n",
    "    all_coefs = pd.DataFrame(all_coefs, columns=dat.columns.values)\n",
    "\n",
    "    return model, all_coefs, y_train_predictions, cross_val_scores, fprs, tprs, interps, aucs\n",
    "\n",
    "# plot count of correct/wrong predictions per class\n",
    "def plot_prediction_counts_per_class(y_real, y_pred, class_labels=None, class_values=None):\n",
    "    compare_predictions = pd.concat(\n",
    "        [y_real, np.abs(y_pred-y_real)], axis=1)\n",
    "    compare_predictions.columns = columns=['real', 'pred_diffs']\n",
    "    y_maxlim = max([\n",
    "            np.histogram(compare_predictions.iloc[:,i], bins=2)[0].max() \n",
    "            for i in range(2)\n",
    "        ])\n",
    "\n",
    "    axes = compare_predictions.hist(\n",
    "        by='real', column='pred_diffs',\n",
    "        bins=2, rwidth=0.4, figsize=(10, 6))\n",
    "    for ax in axes:\n",
    "        ax.set_ylim(0, y_maxlim+1)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_xticks([0.25, 0.75])\n",
    "        ax.set_xticklabels(['correct', 'wrong'], rotation=0, fontsize=14)\n",
    "        if class_labels is not None and class_values is not None:\n",
    "            ax_title = class_labels[class_values == float(ax.get_title())][0]+':'+str(ax.get_title())\n",
    "            ax.set_title(ax_title, fontsize=14)\n",
    "        plt.suptitle('real predictions', fontsize=16)\n",
    "\n",
    "# plot confusion matrix\n",
    "def compute_and_plot_confusion_matrices(y_real, y_pred, class_labels=None, class_values=None):\n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(\n",
    "        y_real,\n",
    "        y_pred.loc[y_real.index])\n",
    "    np.set_printoptions(precision=2)\n",
    "    if class_labels is not None and class_values is not None:\n",
    "        _classes = [\n",
    "            class_labels[class_values == 0][0],\n",
    "            class_labels[class_values == 1][0]]\n",
    "    else:\n",
    "        _classes = ['class_0', 'class_1']\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(\n",
    "        cnf_matrix, classes=_classes,\n",
    "        title='Confusion matrix, without normalization')\n",
    "    plt1 = plt.gcf()\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(\n",
    "        cnf_matrix, classes=_classes, normalize=True,\n",
    "        title='Normalized confusion matrix')\n",
    "    plt2 = plt.gcf()\n",
    "    \n",
    "    return plt1, plt2\n",
    "\n",
    "def plot_roc_for_many_models(model_names, fprs, tprs, aucs, figsize=(10,10)):\n",
    "    n_models = len(model_names)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(n_models):\n",
    "        plt.plot(\n",
    "            fprs[i], tprs[i], #lw=1, alpha=0.3,\n",
    "            label='%s (AUC=%0.2f)' % (model_names[i], aucs[i]))\n",
    "    plt.plot(\n",
    "        [0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curves')\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "def plot_roc_with_std_for_one_model(n_splits, fprs, tprs, interps, aucs, figsize=(10,10), model_name=None):\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(n_splits):\n",
    "        plt.plot(\n",
    "            fprs[i], tprs[i], lw=1, alpha=0.3,\n",
    "            label='ROC fold %d (AUC = %0.2f)' % (i, aucs[i]))\n",
    "    plt.plot(\n",
    "        [0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "\n",
    "    mean_tpr = np.mean(interps, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(interps, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    if model_name is None:\n",
    "        plt.title('Cross-validation training ROC curves\\nwith std for one model')\n",
    "    else:\n",
    "        plt.title('Cross-validation training ROC curves\\nwith std for model: '+model_name)\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "def plot_scatter_scores(y_train_scores, y_test_score=None):\n",
    "    # plot accuracy scores of the train and test data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(\n",
    "        np.arange(len(y_train_scores))+1, sorted(y_train_scores), color='black')\n",
    "    if y_test_score is not None:\n",
    "        plt.scatter(0, y_test_score, color='red')\n",
    "    plt.axhline(0, color='k')\n",
    "    plt.xlim(-1, len(y_train_scores)+1)\n",
    "    plt.ylim(-0.5, 1.5)\n",
    "    plt.xlabel(\"test and train kfolds\")\n",
    "    plt.ylabel(\"accuracy scores\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "START ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = np.array(class_labels)\n",
    "class_values = np.array(class_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly set file paths\n",
    "try:\n",
    "    os.path.exists(MainDataDir)\n",
    "except:\n",
    "    MainDataDir = os.path.join(script_path, '..','..', 'data')\n",
    "    logger.debug(\"set MainDataDir:\\n\"+MainDataDir)\n",
    "\n",
    "# data input\n",
    "data_fpath = check_path_integrity(data_fpath, rootDir=MainDataDir, name=\"data\")\n",
    "\n",
    "# sample info input\n",
    "sample_info_fpath = check_path_integrity(sample_info_fpath, rootDir=MainDataDir, name=\"sample_info\")\n",
    "\n",
    "# gene info input\n",
    "genes_info_fpath = check_path_integrity(genes_info_fpath, rootDir=MainDataDir, name=\"gene_info\")\n",
    "\n",
    "# data output\n",
    "output_directory = check_path_integrity(output_directory, rootDir=MainDataDir, name=\"output\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpaths_dict\n",
    "fpaths_dict = {}\n",
    "fpaths_dict['genepanel'] = check_path_integrity(genepanel_path, rootDir=MainDataDir, name=\"genepanel features\")\n",
    "\n",
    "for _f, _k in zip(_dirs, _key_names):\n",
    "    fpath = \"output/headneck/feature_selection/\"+_f+\"/featsel_results.csv\"\n",
    "    fpaths_dict[_k] = check_path_integrity(fpath, rootDir=MainDataDir, name=_k+\" features\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (cmap_custom is None) and (vmin is not None) and (vmax is not None):\n",
    "    custom_div_cmap_arg = abs(vmin)+abs(vmax)\n",
    "    if (vmin <= 0) and (vmax >= 0):\n",
    "        custom_div_cmap_arg = custom_div_cmap_arg + 1\n",
    "    mincol = plot_kwargs.get('mincol', None)\n",
    "    midcol = plot_kwargs.get('midcol', None)\n",
    "    maxcol = plot_kwargs.get('maxcol', None)\n",
    "    if (\n",
    "            (mincol is not None) and\n",
    "            (midcol is not None) and\n",
    "            (maxcol is not None)\n",
    "            ):\n",
    "        cmap_custom = custom_div_cmap(\n",
    "            numcolors=custom_div_cmap_arg,\n",
    "            mincol=mincol, midcol=midcol, maxcol=maxcol)\n",
    "    else:\n",
    "        cmap_custom = custom_div_cmap(numcolors=custom_div_cmap_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(data_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded data file with shape: '+str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info table of samples\n",
    "sample_info = load_clinical(\n",
    "    sample_info_fpath, **sample_info_read_csv_kwargs)\n",
    "logger.info('loaded sample_info file with shape: '+str(sample_info.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = sample_info.loc[data.index,:]\n",
    "logger.info('keeping part of sample_infowith shape: '+str(sample_info.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info table of genes\n",
    "genes_info = pd.read_csv(genes_info_fpath, sep='\\t', header=0, index_col=0)\n",
    "logger.info('loaded gene_info file with shape: '+str(genes_info.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the ground truth\n",
    "ground_truth = sample_info.loc[data.index, sample_class_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of data w/ duplicates\n",
    "xlabels, xpos = get_chr_ticks(\n",
    "    genes_info, data, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    data, ground_truth, xlabels, xpos, \n",
    "    vmin, vmax, cmap_custom, custom_div_cmap_arg,\n",
    "    function_dict\n",
    ")\n",
    "plt.title('data: '+str(data.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_data\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all zero columns!\n",
    "orphancols = np.where(abs(data).sum(axis=0) == 0)[0]\n",
    "if len(orphancols) > 0:\n",
    "    logger.warning('removing '+str(len(orphancols))+' genes from train data with zero columns!')\n",
    "    cols2drop = data.columns.values[orphancols]\n",
    "    data = data.drop(cols2drop, axis=1).copy()\n",
    "\n",
    "# REMOVE DUPLICATES!!!!\n",
    "data_uniq, dupldict, wo_dupl_set, all_dupl_set = remove_andSave_duplicates(\n",
    "    data, to_compute_euclidean_distances=True,\n",
    "    to_save_euclidean_distances=True, to_save_output=True,\n",
    "    output_filename='data_wo_duplicates',\n",
    "    output_directory=output_directory\n",
    ")\n",
    "single_dupl_set = set(dupldict.keys())\n",
    "\n",
    "_countA = len(set.union(single_dupl_set, wo_dupl_set))\n",
    "_countB = data_uniq.shape[1]\n",
    "if not _countA == _countB:\n",
    "    print(\n",
    "        'ERROR: inconsistencies in the final uniq gene count!\\n'+\n",
    "        str(_countA)+' genes that should be in the uniq dataset VS. '+\n",
    "        str(_countB)+' genes that are'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot Heatmap of data w/o duplicates\n",
    "xlabels_uniq, xpos_uniq = get_chr_ticks(\n",
    "    genes_info, data_uniq, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "plot_data_heatmap(\n",
    "    data_uniq, ground_truth, xlabels_uniq, xpos_uniq, \n",
    "    vmin, vmax, cmap_custom, custom_div_cmap_arg,\n",
    "    function_dict\n",
    ")\n",
    "plt.title('data w/o duplicates: '+str(data_uniq.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_data_uniq\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train-test ONCE!\n",
    "stratify_by = pd.concat([ground_truth, sample_info['dataset']], axis=1, sort=False)\n",
    "stratify_by = stratify_by.loc[ground_truth.index]\n",
    "\n",
    "data_train, data_test, y_train, y_test = train_test_split(\n",
    "    data_uniq, ground_truth,\n",
    "    train_size=split_train_size,\n",
    "    test_size=None,\n",
    "    random_state=split_random_state,\n",
    "    stratify=stratify_by\n",
    ")\n",
    "\n",
    "stratify_by.hist()\n",
    "plt.suptitle('all '+str(ground_truth.shape[0])+' samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_all\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[data_train.index].hist()\n",
    "plt.suptitle(str(y_train.shape[0])+' train samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_train\", img_ext=img_ext)\n",
    "\n",
    "stratify_by.loc[data_test.index].hist()\n",
    "plt.suptitle(str(y_test.shape[0])+' test samples', fontsize=16)\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"stratify_by_test\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels_train, xpos_train = get_chr_ticks(\n",
    "    genes_info, data_train, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "xlabels_test, xpos_test = get_chr_ticks(\n",
    "    genes_info, data_test, id_col=gene_id_col, chr_col=chr_col)\n",
    "\n",
    "#  Plot Heatmap of train data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    data_train, y_train, xlabels_train, xpos_train, \n",
    "    vmin, vmax, cmap_custom, custom_div_cmap_arg,\n",
    "    function_dict\n",
    ")\n",
    "plt.title('train data: '+str(data_train.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_data_train\", img_ext=img_ext)\n",
    "\n",
    "#  Plot Heatmap of test data (w/o duplicates)\n",
    "plot_data_heatmap(\n",
    "    data_test, y_test, xlabels_test, xpos_test, \n",
    "    vmin, vmax, cmap_custom, custom_div_cmap_arg,\n",
    "    function_dict\n",
    ")\n",
    "plt.title('test data: '+str(data_test.shape[1])+' gene profiles')\n",
    "save_image(saveReport=saveReport, output_directory=output_directory, img_name=\"heatmap_data_test\", img_ext=img_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_genes = set(data.columns.values)\n",
    "all_data_genes_uniq = set(data_uniq.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {}\n",
    "features_sets = {}\n",
    "for key in fpaths_dict:\n",
    "    \n",
    "    df = pd.read_csv(fpaths_dict[key], sep='\\t', header=0, index_col=0)\n",
    "    \n",
    "    if 'genepanel' in key:\n",
    "        features_sets[key] = set(df.columns.values)\n",
    "        n_total = len(features_sets[key])\n",
    "        n_unique = n_total\n",
    "    else:\n",
    "        features_dict[key] = df\n",
    "        features_sets[key] = extract_gene_set(df)\n",
    "        n_total = len(features_sets[key])\n",
    "        n_unique = df.shape[0]\n",
    "        \n",
    "    logger.info(str(n_unique)+' unique out of '+str(n_total)+' total features from '+key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venn diagrams to explain the functionality of the cell below:<br>\n",
    "U --> data uniq genes (genes w/o dupl + single copy duplicates genes) <br>\n",
    "D --> the rest of the duplicates genes copies<br>\n",
    "fs --> a single features set<br>\n",
    "IU --> the features that exist in the U set<br>\n",
    "ID --> the features that exist in the D set<br>\n",
    "NI --> the features that do NOT exist in neither set<br>\n",
    "IDa --> the features that exist in the ID set and are not represented in the IU set<br>\n",
    "IDb --> the features that exist in the ID set and are already represented in the IU set<br>\n",
    "_ID = IDa + IDb_<br>\n",
    "U_IDa --> the features that exist in the U set (but not in the IU set) and represent the IDa features<br>\n",
    "**fs in data_uniq = IU + U_IDa**<br>\n",
    "<img src=\"./files/venn_legend.jpg?1\" alt=\"drawing\" style=\"float:left\" width=\"300px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# U: all_data_genes_uniq\n",
    "# D: all_dupl_set.difference(all_data_genes_uniq)\n",
    "# fs: features_sets[key]\n",
    "new_features_sets = {}\n",
    "\n",
    "U_set = all_data_genes_uniq\n",
    "D_set = all_dupl_set.difference(all_data_genes_uniq)\n",
    "for key in features_sets:\n",
    "    fs = features_sets[key]\n",
    "    _fs_original_size = len(fs)\n",
    "    print(key+' feature set :')\n",
    "    print('--- originally ---')\n",
    "    print(' original total size: '+str(_fs_original_size))\n",
    "    IU_set = fs.intersection(U_set)\n",
    "    _IU_size = len(IU_set)\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "\n",
    "    ID_set = (fs.difference(IU_set)).intersection(D_set)\n",
    "    _ID_size = len(ID_set)\n",
    "    print(' ID_set: '+str(_ID_size))\n",
    "\n",
    "    NI_set = (fs.difference(IU_set)).difference(ID_set)\n",
    "    _NI_size =len(NI_set)\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    U_IDa_set = set()\n",
    "    IDa_set = set()\n",
    "    IDb_set = set()\n",
    "    IDc_set = set()\n",
    "    done = False\n",
    "    temp_set = ID_set.copy()\n",
    "    while temp_set and not done:\n",
    "        for ud, dl in dupldict.items():\n",
    "            _IDx = set(dl).intersection(temp_set)\n",
    "            if _IDx:\n",
    "                temp_set = temp_set.difference(_IDx)\n",
    "                if ud not in IU_set:\n",
    "                    U_IDa_set.add(ud)\n",
    "                    IDa_set.update(_IDx)\n",
    "                else:\n",
    "                    IDb_set.update(_IDx) \n",
    "        done = True\n",
    "\n",
    "    fs_in_data_uniq = set.union(IU_set, U_IDa_set)\n",
    "    _fs_in_data_uniq_size = len(fs_in_data_uniq)\n",
    "\n",
    "    ########################################\n",
    "    new_features_sets[key] = fs_in_data_uniq\n",
    "    ########################################\n",
    "    \n",
    "    print('--- finally ---')\n",
    "    print(' features in data uniq : '+str(_fs_in_data_uniq_size))\n",
    "    print(' IU_set: '+str(_IU_size))\n",
    "    print('   U_IDa_set: '+str(len(U_IDa_set)))\n",
    "    print(' ID_set: '+str(len(ID_set)))\n",
    "    print('   IDa_set: '+str(len(IDa_set)))\n",
    "    print('   IDb_set: '+str(len(IDb_set)))\n",
    "    print(' NI_set: '+str(_NI_size))\n",
    "\n",
    "    if ID_set != set.union(IDa_set, IDb_set):\n",
    "        print(\n",
    "            'ERROR: something went wrong, ID_set != IDa_set + IDb_set, for feature set: '+key\n",
    "        )\n",
    "        break\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_fprs = []\n",
    "fs_tprs = []\n",
    "fs_aucs = []\n",
    "for key in new_features_sets:\n",
    "    fset = list(new_features_sets[key])\n",
    "    X_train = data_train.loc[:,fset].copy()\n",
    "    X_test = data_test.loc[:,fset].copy()\n",
    "\n",
    "    # train model\n",
    "    model, all_coefs, y_train_predictions, y_train_scores, fprs, tprs, interps, aucs = \\\n",
    "        _run_classification(\n",
    "            X_train, y_train, **classification_args)\n",
    "\n",
    "    # plot_prediction_counts_per_class\n",
    "    plot_prediction_counts_per_class(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"count_predictions_per_class\", img_ext=img_ext)\n",
    "\n",
    "    # compute_and_plot_confusion_matrices\n",
    "    plt1, plt2 = compute_and_plot_confusion_matrices(\n",
    "        y_train, y_train_predictions, class_labels=class_labels, class_values=class_values)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix\", img_ext=img_ext, plt_obj=plt1)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"confusion_matrix_normalized\", img_ext=img_ext, plt_obj=plt2)\n",
    "\n",
    "    # plot_roc_with_std_for_one_model\n",
    "    n_splits = classification_args[\"n_splits\"]\n",
    "    plot_roc_with_std_for_one_model(n_splits, fprs, tprs, interps, aucs, figsize=(10,10), model_name=key)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"train_crossval_roc_curves_\"+key, img_ext=img_ext)\n",
    "\n",
    "    # Test the model\n",
    "    y_test_score = model.score(X_test, y_test)\n",
    "    y_test_predictions = model.predict(X_test)\n",
    "    y_test_predictions = pd.Series(y_test_predictions, index=X_test.index)\n",
    "    y_test_predictions.name = 'test_predictions'\n",
    "\n",
    "    plot_scatter_scores(y_train_scores, y_test_score)\n",
    "    save_image(\n",
    "        saveReport=saveReport, output_directory=output_directory, \n",
    "        img_name=\"scatter_scores\", img_ext=img_ext)\n",
    "    \n",
    "    #  prepare for the ROC curves on each feature set\n",
    "    clf = CalibratedClassifierCV(base_estimator=model, cv='prefit')\n",
    "    clf.fit(X_test, y_test)\n",
    "    y_proba = clf.predict_proba(X_test)\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])\n",
    "    fs_fprs.append(fpr)\n",
    "    fs_tprs.append(tpr)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fs_aucs.append(roc_auc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_for_many_models(list(new_features_sets.keys()), fs_fprs, fs_tprs, fs_aucs, figsize=(10,10))\n",
    "save_image(\n",
    "    saveReport=saveReport, output_directory=output_directory, \n",
    "    img_name=\"test_all_models_roc_curves\", img_ext=img_ext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
